{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7eNFgeUxEBav",
        "outputId": "e266bd5c-07d5-49b6-8347-92b4c40c4a2a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytube transformers moviepy TTS youtube_transcript_api pydub SentencePiece pysubs2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nybTo9IuJOUI",
        "outputId": "9d4b4122-3894-4463-f452-11553ad86052"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytube\n",
            "  Downloading pytube-15.0.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m920.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.10/dist-packages (1.0.3)\n",
            "Collecting TTS\n",
            "  Downloading TTS-0.21.3-cp310-cp310-manylinux1_x86_64.whl (942 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m942.6/942.6 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting youtube_transcript_api\n",
            "  Downloading youtube_transcript_api-0.6.1-py3-none-any.whl (24 kB)\n",
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting SentencePiece\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pysubs2\n",
            "  Downloading pysubs2-1.6.1-py3-none-any.whl (35 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.1.10)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.31.6)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.4.9)\n",
            "Requirement already satisfied: cython>=0.29.30 in /usr/local/lib/python3.10/dist-packages (from TTS) (3.0.6)\n",
            "Requirement already satisfied: scipy>=1.11.2 in /usr/local/lib/python3.10/dist-packages (from TTS) (1.11.4)\n",
            "Requirement already satisfied: torch>=2.1 in /usr/local/lib/python3.10/dist-packages (from TTS) (2.1.0+cu118)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (from TTS) (2.1.0+cu118)\n",
            "Requirement already satisfied: soundfile>=0.12.0 in /usr/local/lib/python3.10/dist-packages (from TTS) (0.12.1)\n",
            "Requirement already satisfied: librosa>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from TTS) (0.10.1)\n",
            "Collecting scikit-learn>=1.3.0 (from TTS)\n",
            "  Downloading scikit_learn-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m44.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: inflect>=5.6.0 in /usr/local/lib/python3.10/dist-packages (from TTS) (7.0.0)\n",
            "Collecting anyascii>=0.3.0 (from TTS)\n",
            "  Downloading anyascii-0.3.2-py3-none-any.whl (289 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.9/289.9 kB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec>=2023.6.0 in /usr/local/lib/python3.10/dist-packages (from TTS) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from TTS) (3.9.1)\n",
            "Requirement already satisfied: flask>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from TTS) (2.2.5)\n",
            "Collecting pysbd>=0.3.4 (from TTS)\n",
            "  Downloading pysbd-0.3.4-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting umap-learn>=0.5.1 (from TTS)\n",
            "  Downloading umap-learn-0.5.5.tar.gz (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.9/90.9 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pandas<2.0,>=1.4 in /usr/local/lib/python3.10/dist-packages (from TTS) (1.5.3)\n",
            "Requirement already satisfied: matplotlib>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from TTS) (3.7.1)\n",
            "Collecting trainer>=0.0.32 (from TTS)\n",
            "  Downloading trainer-0.0.33-py3-none-any.whl (51 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.1/51.1 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting coqpit>=0.0.16 (from TTS)\n",
            "  Downloading coqpit-0.0.17-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.10/dist-packages (from TTS) (0.42.1)\n",
            "Collecting pypinyin (from TTS)\n",
            "  Downloading pypinyin-0.49.0-py2.py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m55.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting hangul-romanize (from TTS)\n",
            "  Downloading hangul_romanize-0.1.0-py3-none-any.whl (4.6 kB)\n",
            "Collecting gruut[de,es,fr]==2.2.3 (from TTS)\n",
            "  Downloading gruut-2.2.3.tar.gz (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.5/73.5 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jamo (from TTS)\n",
            "  Downloading jamo-0.4.1-py3-none-any.whl (9.5 kB)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from TTS) (3.8.1)\n",
            "Collecting g2pkk>=0.1.1 (from TTS)\n",
            "  Downloading g2pkk-0.1.2-py3-none-any.whl (25 kB)\n",
            "Collecting bangla (from TTS)\n",
            "  Downloading bangla-0.0.2-py2.py3-none-any.whl (6.2 kB)\n",
            "Collecting bnnumerizer (from TTS)\n",
            "  Downloading bnnumerizer-0.0.2.tar.gz (4.7 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting bnunicodenormalizer (from TTS)\n",
            "  Downloading bnunicodenormalizer-0.1.6.tar.gz (39 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting einops>=0.6.0 (from TTS)\n",
            "  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting encodec>=0.1.1 (from TTS)\n",
            "  Downloading encodec-0.1.1.tar.gz (3.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m68.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting unidecode>=1.3.2 (from TTS)\n",
            "  Downloading Unidecode-1.3.7-py3-none-any.whl (235 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.5/235.5 kB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting num2words (from TTS)\n",
            "  Downloading num2words-0.5.13-py3-none-any.whl (143 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.3/143.3 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy[ja]>=3 in /usr/local/lib/python3.10/dist-packages (from TTS) (3.6.1)\n",
            "Collecting numpy>=1.17 (from transformers)\n",
            "  Downloading numpy-1.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numba>=0.57.0 in /usr/local/lib/python3.10/dist-packages (from TTS) (0.58.1)\n",
            "Requirement already satisfied: Babel<3.0.0,>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from gruut[de,es,fr]==2.2.3->TTS) (2.13.1)\n",
            "Collecting dateparser~=1.1.0 (from gruut[de,es,fr]==2.2.3->TTS)\n",
            "  Downloading dateparser-1.1.8-py2.py3-none-any.whl (293 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m293.8/293.8 kB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gruut-ipa<1.0,>=0.12.0 (from gruut[de,es,fr]==2.2.3->TTS)\n",
            "  Downloading gruut-ipa-0.13.0.tar.gz (101 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gruut_lang_en~=2.0.0 (from gruut[de,es,fr]==2.2.3->TTS)\n",
            "  Downloading gruut_lang_en-2.0.0.tar.gz (15.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.2/15.2 MB\u001b[0m \u001b[31m91.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jsonlines~=1.2.0 (from gruut[de,es,fr]==2.2.3->TTS)\n",
            "  Downloading jsonlines-1.2.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Collecting networkx<3.0.0,>=2.5.0 (from gruut[de,es,fr]==2.2.3->TTS)\n",
            "  Downloading networkx-2.8.8-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m100.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-crfsuite~=0.9.7 (from gruut[de,es,fr]==2.2.3->TTS)\n",
            "  Downloading python_crfsuite-0.9.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (993 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m993.5/993.5 kB\u001b[0m \u001b[31m72.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gruut_lang_es~=2.0.0 (from gruut[de,es,fr]==2.2.3->TTS)\n",
            "  Downloading gruut_lang_es-2.0.0.tar.gz (31.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gruut_lang_fr~=2.0.0 (from gruut[de,es,fr]==2.2.3->TTS)\n",
            "  Downloading gruut_lang_fr-2.0.2.tar.gz (10.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m74.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gruut_lang_de~=2.0.0 (from gruut[de,es,fr]==2.2.3->TTS)\n",
            "  Downloading gruut_lang_de-2.0.0.tar.gz (18.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.1->TTS) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.1->TTS) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.1->TTS) (1.9.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.1->TTS) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.1->TTS) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.1->TTS) (4.0.3)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from flask>=2.0.1->TTS) (3.0.1)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from flask>=2.0.1->TTS) (3.1.2)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from flask>=2.0.1->TTS) (2.1.2)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from flask>=2.0.1->TTS) (8.1.7)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: pillow<10.1.0,>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio<3.0,>=2.5->moviepy) (9.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from imageio-ffmpeg>=0.2.0->moviepy) (67.7.2)\n",
            "Requirement already satisfied: pydantic>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from inflect>=5.6.0->TTS) (1.10.13)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->TTS) (3.0.1)\n",
            "INFO: pip is looking at multiple versions of librosa to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting librosa>=0.10.0 (from TTS)\n",
            "  Downloading librosa-0.10.0.post2-py3-none-any.whl (253 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.0/253.0 kB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading librosa-0.10.0.post1-py3-none-any.whl (252 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.0/253.0 kB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading librosa-0.10.0-py3-none-any.whl (252 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.9/252.9 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->TTS) (1.3.2)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->TTS) (1.8.0)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->TTS) (0.3.7)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->TTS) (0.3)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->TTS) (1.0.7)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->TTS) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->TTS) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->TTS) (4.45.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->TTS) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->TTS) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->TTS) (2.8.2)\n",
            "Collecting docopt>=0.6.2 (from num2words->TTS)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.57.0->TTS) (0.41.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.0,>=1.4->TTS) (2023.3.post1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.0->TTS) (3.2.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.0->TTS) (1.16.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy[ja]>=3->TTS) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy[ja]>=3->TTS) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy[ja]>=3->TTS) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy[ja]>=3->TTS) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy[ja]>=3->TTS) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy[ja]>=3->TTS) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy[ja]>=3->TTS) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy[ja]>=3->TTS) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy[ja]>=3->TTS) (2.0.10)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy[ja]>=3->TTS) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy[ja]>=3->TTS) (0.10.3)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy[ja]>=3->TTS) (6.4.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy[ja]>=3->TTS) (3.3.0)\n",
            "Collecting sudachipy!=0.6.1,>=0.5.2 (from spacy[ja]>=3->TTS)\n",
            "  Downloading SudachiPy-0.6.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m95.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sudachidict-core>=20211220 (from spacy[ja]>=3->TTS)\n",
            "  Downloading SudachiDict_core-20230927-py3-none-any.whl (71.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.7/71.7 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.1->TTS) (1.12)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1->TTS) (2.1.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from trainer>=0.0.32->TTS) (5.9.5)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from trainer>=0.0.32->TTS) (2.14.1)\n",
            "Collecting pynndescent>=0.5 (from umap-learn>=0.5.1->TTS)\n",
            "  Downloading pynndescent-0.5.11-py3-none-any.whl (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.0->TTS) (2.21)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.10/dist-packages (from dateparser~=1.1.0->gruut[de,es,fr]==2.2.3->TTS) (5.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->flask>=2.0.1->TTS) (2.1.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from jsonlines~=1.2.0->gruut[de,es,fr]==2.2.3->TTS) (1.16.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa>=0.10.0->TTS) (4.0.0)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy[ja]>=3->TTS) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy[ja]>=3->TTS) (0.1.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.1->TTS) (1.3.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer>=0.0.32->TTS) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer>=0.0.32->TTS) (1.59.3)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer>=0.0.32->TTS) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer>=0.0.32->TTS) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer>=0.0.32->TTS) (3.5.1)\n",
            "Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer>=0.0.32->TTS) (3.20.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer>=0.0.32->TTS) (0.7.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->trainer>=0.0.32->TTS) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->trainer>=0.0.32->TTS) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->trainer>=0.0.32->TTS) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard->trainer>=0.0.32->TTS) (1.3.1)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->trainer>=0.0.32->TTS) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard->trainer>=0.0.32->TTS) (3.2.2)\n",
            "Building wheels for collected packages: encodec, umap-learn, bnnumerizer, bnunicodenormalizer, docopt, gruut-ipa, gruut_lang_de, gruut_lang_en, gruut_lang_es, gruut_lang_fr, gruut\n",
            "  Building wheel for encodec (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for encodec: filename=encodec-0.1.1-py3-none-any.whl size=45759 sha256=4cb73b135f268c1163f8623ae69e44b9b6f83343b19548e10f92493e0c712e04\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/36/cb/81af8b985a5f5e0815312d5e52b41263237af07b977e6bcbf3\n",
            "  Building wheel for umap-learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for umap-learn: filename=umap_learn-0.5.5-py3-none-any.whl size=86832 sha256=d6a6d95eb7ef5ac5677dc009003b6b4a12d55d7636cd8e2c15fa7fde197b7a54\n",
            "  Stored in directory: /root/.cache/pip/wheels/3a/70/07/428d2b58660a1a3b431db59b806a10da736612ebbc66c1bcc5\n",
            "  Building wheel for bnnumerizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bnnumerizer: filename=bnnumerizer-0.0.2-py3-none-any.whl size=5259 sha256=2018ab20c26a53aec86d657015e1e6ab7a5add58a5046b013c20bbb8ea240f2d\n",
            "  Stored in directory: /root/.cache/pip/wheels/59/6b/e8/223172e7d5c9f72df3ea1a0d9258f3a8ab5b28e827728edef5\n",
            "  Building wheel for bnunicodenormalizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bnunicodenormalizer: filename=bnunicodenormalizer-0.1.6-py3-none-any.whl size=22779 sha256=a69b6d6095254853a276fcfc6d578b6bab34580b9a382064c94c118883e0f727\n",
            "  Stored in directory: /root/.cache/pip/wheels/f4/d7/e9/16732a619cbf5a63fdc9f6e2f9eb5fcf73fa023735237330e9\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=9bca5fc5d62df0382f3a446aaf6ef5c44714a13a32846f68ac29f1a446554503\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "  Building wheel for gruut-ipa (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut-ipa: filename=gruut_ipa-0.13.0-py3-none-any.whl size=104873 sha256=74f13750ee89af548dc84367579ce514fe86bbca8243d8a17d1b4edfdecf3d97\n",
            "  Stored in directory: /root/.cache/pip/wheels/7b/18/49/e4f500ecdf0babe757953f844e4d7cd1ea81c5503c09bfe984\n",
            "  Building wheel for gruut_lang_de (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut_lang_de: filename=gruut_lang_de-2.0.0-py3-none-any.whl size=18498182 sha256=61147a5416da7a329889a0e3f69eafe08564390d4e0ae616baa659468debe4bc\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/9a/05/cfce98f0c41a1a540f15708c4a02df190b82d84cf91ef6bc7f\n",
            "  Building wheel for gruut_lang_en (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut_lang_en: filename=gruut_lang_en-2.0.0-py3-none-any.whl size=15297178 sha256=a3eb6004daf8812999015d7befb4a1bf0b873155960caa916b9729d4591b6bbc\n",
            "  Stored in directory: /root/.cache/pip/wheels/10/9c/fb/77c655a9fbd78cdb9935d0ab65d80ddd0a3bcf7dbe18261650\n",
            "  Building wheel for gruut_lang_es (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut_lang_es: filename=gruut_lang_es-2.0.0-py3-none-any.whl size=32173796 sha256=6d27856d89a1e728e9a7ecc37875a0063b3e37aa9c52cb35b7b30e2582546177\n",
            "  Stored in directory: /root/.cache/pip/wheels/9b/0a/90/788d92c07744b329b9283e37b29b064f5db6b1bb0442a1a19b\n",
            "  Building wheel for gruut_lang_fr (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut_lang_fr: filename=gruut_lang_fr-2.0.2-py3-none-any.whl size=10968766 sha256=2f42fed04ec3df89a5f36c5613f79714eecda7d2ccebd8789114366fdd0fbc6d\n",
            "  Stored in directory: /root/.cache/pip/wheels/db/21/be/d0436e3f1cf9bf38b9bb9b4a476399c77a1ab19f7172b45e19\n",
            "  Building wheel for gruut (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut: filename=gruut-2.2.3-py3-none-any.whl size=75792 sha256=eb8d4a7cd0d833e8cbdc65d48d889c62efa82cc80477acbb9182eb397badfd8c\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/57/a8/f9de532daf5214f53644f20f3a9e6f69269453c87df9c0a817\n",
            "Successfully built encodec umap-learn bnnumerizer bnunicodenormalizer docopt gruut-ipa gruut_lang_de gruut_lang_en gruut_lang_es gruut_lang_fr gruut\n",
            "Installing collected packages: sudachipy, SentencePiece, python-crfsuite, pydub, jamo, hangul-romanize, gruut_lang_fr, gruut_lang_es, gruut_lang_en, gruut_lang_de, docopt, bnunicodenormalizer, bnnumerizer, bangla, unidecode, sudachidict-core, pytube, pysubs2, pysbd, pypinyin, numpy, num2words, networkx, jsonlines, gruut-ipa, einops, coqpit, anyascii, youtube_transcript_api, g2pkk, dateparser, scikit-learn, gruut, pynndescent, librosa, encodec, umap-learn, trainer, TTS\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.23.5\n",
            "    Uninstalling numpy-1.23.5:\n",
            "      Successfully uninstalled numpy-1.23.5\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.2.1\n",
            "    Uninstalling networkx-3.2.1:\n",
            "      Successfully uninstalled networkx-3.2.1\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.2.2\n",
            "    Uninstalling scikit-learn-1.2.2:\n",
            "      Successfully uninstalled scikit-learn-1.2.2\n",
            "  Attempting uninstall: librosa\n",
            "    Found existing installation: librosa 0.10.1\n",
            "    Uninstalling librosa-0.10.1:\n",
            "      Successfully uninstalled librosa-0.10.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "plotnine 0.12.4 requires numpy>=1.23.0, but you have numpy 1.22.0 which is incompatible.\n",
            "pywavelets 1.5.0 requires numpy<2.0,>=1.22.4, but you have numpy 1.22.0 which is incompatible.\n",
            "tensorflow 2.14.0 requires numpy>=1.23.5, but you have numpy 1.22.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed SentencePiece-0.1.99 TTS-0.21.3 anyascii-0.3.2 bangla-0.0.2 bnnumerizer-0.0.2 bnunicodenormalizer-0.1.6 coqpit-0.0.17 dateparser-1.1.8 docopt-0.6.2 einops-0.7.0 encodec-0.1.1 g2pkk-0.1.2 gruut-2.2.3 gruut-ipa-0.13.0 gruut_lang_de-2.0.0 gruut_lang_en-2.0.0 gruut_lang_es-2.0.0 gruut_lang_fr-2.0.2 hangul-romanize-0.1.0 jamo-0.4.1 jsonlines-1.2.0 librosa-0.10.0 networkx-2.8.8 num2words-0.5.13 numpy-1.22.0 pydub-0.25.1 pynndescent-0.5.11 pypinyin-0.49.0 pysbd-0.3.4 pysubs2-1.6.1 python-crfsuite-0.9.9 pytube-15.0.0 scikit-learn-1.3.2 sudachidict-core-20230927 sudachipy-0.6.7 trainer-0.0.33 umap-learn-0.5.5 unidecode-1.3.7 youtube_transcript_api-0.6.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7CadmpsIJA3v",
        "outputId": "b013c25c-5caf-4bc9-dc27-bd2c57268be1"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/transformers/models/marian/tokenization_marian.py:197: UserWarning: Recommended: pip install sacremoses.\n",
            "  warnings.warn(\"Recommended: pip install sacremoses.\")\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " > tts_models/fr/css10/vits is already downloaded.\n",
            " > Using model: vits\n",
            " > Setting up Audio Processor...\n",
            " | > sample_rate:22050\n",
            " | > resample:False\n",
            " | > num_mels:80\n",
            " | > log_func:np.log10\n",
            " | > min_level_db:0\n",
            " | > frame_shift_ms:None\n",
            " | > frame_length_ms:None\n",
            " | > ref_level_db:None\n",
            " | > fft_size:1024\n",
            " | > power:None\n",
            " | > preemphasis:0.0\n",
            " | > griffin_lim_iters:None\n",
            " | > signal_norm:None\n",
            " | > symmetric_norm:None\n",
            " | > mel_fmin:0\n",
            " | > mel_fmax:None\n",
            " | > pitch_fmin:None\n",
            " | > pitch_fmax:None\n",
            " | > spec_gain:20.0\n",
            " | > stft_pad_mode:reflect\n",
            " | > max_norm:1.0\n",
            " | > clip_norm:True\n",
            " | > do_trim_silence:False\n",
            " | > trim_db:60\n",
            " | > do_sound_norm:False\n",
            " | > do_amp_to_db_linear:True\n",
            " | > do_amp_to_db_mel:True\n",
            " | > do_rms_norm:False\n",
            " | > db_level:None\n",
            " | > stats_path:None\n",
            " | > base:10\n",
            " | > hop_length:256\n",
            " | > win_length:1024\n",
            " > initialization of speaker-embedding layers.\n",
            " > initialization of language-embedding layers.\n",
            "MoviePy - Writing audio in /content/drive/MyDrive/Colab Notebooks/CS370_project/videos7/audio/I Remastered GTA 4 (Sorry Rockstar).mp3\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MoviePy - Done.\n",
            " > Text splitted to sentences.\n",
            "[\"Ce n'est pas un secret.\", \"J'essaie de me faire engager par Rockstar.\"]\n",
            " > Processing time: 0.7204089164733887\n",
            " > Real-time factor: 0.16497400099948303\n",
            " > Text splitted to sentences.\n",
            "[\"J'ai fait tellement de concepts de GTA.\"]\n",
            " > Processing time: 0.5398633480072021\n",
            " > Real-time factor: 0.23127111484999238\n",
            " > Text splitted to sentences.\n",
            "['Si ça ne me fait pas engager, je démissionne.']\n",
            " > Processing time: 0.8234617710113525\n",
            " > Real-time factor: 0.27273089477890416\n",
            " > Text splitted to sentences.\n",
            "[\"Voir la carte de Liberty City de GTA 4 est en fait un chef-d'œuvre.\"]\n",
            "voir la carte de liberty city de gta 4 est en fait un chef d'œuvre.\n",
            " [!] Character '4' not found in the vocabulary. Discarding it.\n",
            " > Processing time: 1.1379461288452148\n",
            " > Real-time factor: 0.2768282451570718\n",
            " > Text splitted to sentences.\n",
            "[\"Je veux dire, c'est tellement en avance sur son temps pour un match fait il y a 15 ans.\"]\n",
            "je veux dire, c'est tellement en avance sur son temps pour un match fait il y a 15 ans.\n",
            " [!] Character '1' not found in the vocabulary. Discarding it.\n",
            "je veux dire, c'est tellement en avance sur son temps pour un match fait il y a 15 ans.\n",
            " [!] Character '5' not found in the vocabulary. Discarding it.\n",
            " > Processing time: 1.2605509757995605\n",
            " > Real-time factor: 0.29339584758043735\n",
            " > Text splitted to sentences.\n",
            "['Ce remaster est certainement mon plus ambitieux encore, donc si je veux faire ce bien,']\n",
            " > Processing time: 1.3601367473602295\n",
            " > Real-time factor: 0.28089891427481134\n",
            " > Text splitted to sentences.\n",
            "['Je dois aller dans la vraie ville sur laquelle il est basé.']\n",
            " > Processing time: 0.9780914783477783\n",
            " > Real-time factor: 0.28746690522457496\n",
            " > Text splitted to sentences.\n",
            "[\"Je suis à New York pendant quatre jours pour recueillir toutes les données dont j'ai besoin pour faire le meilleur remaster.\"]\n",
            " > Processing time: 0.9897482395172119\n",
            " > Real-time factor: 0.17721148403074674\n",
            " > Text splitted to sentences.\n",
            "['Mais je ne peux pas recréer Liberty City.']\n",
            " > Processing time: 0.4836885929107666\n",
            " > Real-time factor: 0.17069995956597958\n",
            " > Text splitted to sentences.\n",
            "['Notre mission est donc de recréer la Statue de la Liberté, Time Square, et quelques autres quêtes.']\n",
            " > Processing time: 1.1010346412658691\n",
            " > Real-time factor: 0.1820035222495533\n",
            " > Text splitted to sentences.\n",
            "[\"Mais avant d'arriver à la ville pour commencer ces missions principales,\"]\n",
            " > Processing time: 0.7110044956207275\n",
            " > Real-time factor: 0.16914432427538667\n",
            " > Text splitted to sentences.\n",
            "[\"Il nous faut d'abord un remaster de Nico Bellic.\"]\n",
            " > Processing time: 0.5332953929901123\n",
            " > Real-time factor: 0.17264451807951572\n",
            " > Text splitted to sentences.\n",
            "[\"J'ai passé un peu trop de temps sur CJ de l'épisode précédent.\"]\n",
            " > Processing time: 1.0529320240020752\n",
            " > Real-time factor: 0.2860382309437926\n",
            " > Text splitted to sentences.\n",
            "['Juste pour que tu les voies à peine.']\n",
            " > Processing time: 0.6453492641448975\n",
            " > Real-time factor: 0.2820716633839793\n",
            " > Text splitted to sentences.\n",
            "[\"Donc pour Nico, j'étais comme, tant qu'il est de la même forme, je vais aller bien.\"]\n",
            " > Processing time: 1.424666404724121\n",
            " > Real-time factor: 0.2873362196707785\n",
            " > Text splitted to sentences.\n",
            "[\"Si vite, peu de temps s'écoule et moi essayant de recréer un autre mâle, ça finit bien.\"]\n",
            " > Processing time: 1.580249309539795\n",
            " > Real-time factor: 0.28060573118277665\n",
            " > Text splitted to sentences.\n",
            "['On a eu Nico original, et ma version.']\n",
            " > Processing time: 0.9164037704467773\n",
            " > Real-time factor: 0.2749660235460407\n",
            " > Text splitted to sentences.\n",
            "[\"Je veux dire, c'est bon, genre...\"]\n",
            " > Processing time: 0.5869045257568359\n",
            " > Real-time factor: 0.27464441411159235\n",
            " > Text splitted to sentences.\n",
            "['Faites-moi savoir ce que vous en pensez.', \"Je dirais que c'est assez proche.\"]\n",
            " > Processing time: 1.3582704067230225\n",
            " > Real-time factor: 0.28182270464696857\n",
            " > Text splitted to sentences.\n",
            "['Je vous demande pardon.']\n",
            " > Processing time: 0.2830932140350342\n",
            " > Real-time factor: 0.16693959588875973\n",
            " > Text splitted to sentences.\n",
            "['Je mets tout le vrai effort dans Time Square,']\n",
            " > Processing time: 0.4437119960784912\n",
            " > Real-time factor: 0.17056920351343674\n",
            " > Text splitted to sentences.\n",
            "[\"C'est là que je vais voir ce que je vais faire avec ce projet.\"]\n",
            " > Processing time: 0.5793068408966064\n",
            " > Real-time factor: 0.17753107407396837\n",
            " > Text splitted to sentences.\n",
            "[\"Parce que je veux dire, c'est à ça que ressemble la version GTA IV.\"]\n",
            " > Processing time: 0.7111029624938965\n",
            " > Real-time factor: 0.17201839041370917\n",
            " > Text splitted to sentences.\n",
            "[\"Et c'est ce que je suis censé recréer.\"]\n",
            " > Processing time: 0.41338086128234863\n",
            " > Real-time factor: 0.17279056701690526\n",
            " > Text splitted to sentences.\n",
            "['Je ne sais pas comment...']\n",
            " > Processing time: 0.26612091064453125\n",
            " > Real-time factor: 0.16846480476894563\n",
            " > Text splitted to sentences.\n",
            "['Il y a infiniment de détails dans les matériaux, la disposition, les textures qui ont été organiques.']\n",
            " > Processing time: 1.372422218322754\n",
            " > Real-time factor: 0.24471074778445404\n",
            " > Text splitted to sentences.\n",
            "[\"J'ai fait des années et des années, et je dois recréer ça d'une façon ou d'une autre.\"]\n",
            " > Processing time: 1.2578163146972656\n",
            " > Real-time factor: 0.2896287566737125\n",
            " > Text splitted to sentences.\n",
            "[\"Ça fait que ma patinoire et ma petite Grove Street cul-de-sac ressemblent à un jouet McDonald's.\"]\n",
            " > Processing time: 1.6823256015777588\n",
            " > Real-time factor: 0.2981168792174809\n",
            " > Text splitted to sentences.\n",
            "[\"Je n'ai même pas mentionné toutes les annonces, frérot, comme quoi?\"]\n",
            " > Processing time: 1.194448709487915\n",
            " > Real-time factor: 0.29729088455174874\n",
            " > Text splitted to sentences.\n",
            "['Je dois recréer toutes ces annonces, donc je vais commencer par celle-ci.']\n",
            " > Processing time: 1.173365592956543\n",
            " > Real-time factor: 0.2954585159497964\n",
            " > Text splitted to sentences.\n",
            "['OperaGX est venu en embrayage pour sponsoriser ce voyage.']\n",
            " > Processing time: 1.1936945915222168\n",
            " > Real-time factor: 0.28476031832119697\n",
            " > Text splitted to sentences.\n",
            "[\"Il n'y a tout simplement aucun autre navigateur qui a une barre latérale qui vous permettra de faire défiler vers le bas TikTok.\"]\n",
            " > Processing time: 1.90458345413208\n",
            " > Real-time factor: 0.29661589701952457\n",
            " > Text splitted to sentences.\n",
            "['Regarde ça, Gordon.']\n",
            " > Processing time: 0.39568567276000977\n",
            " > Real-time factor: 0.16783758626420084\n",
            " > Text splitted to sentences.\n",
            "['Stock Instagram.']\n",
            " > Processing time: 0.24847888946533203\n",
            " > Real-time factor: 0.16455308483633382\n",
            " > Text splitted to sentences.\n",
            "['Tout en attendant que votre streamer préféré aille en direct.']\n",
            " > Processing time: 0.6192431449890137\n",
            " > Real-time factor: 0.17484008588157846\n",
            " > Text splitted to sentences.\n",
            "['Jamais une vignette.']\n",
            " > Processing time: 0.3407750129699707\n",
            " > Real-time factor: 0.17259484187770704\n",
            " > Text splitted to sentences.\n",
            "[\"Je veux dire, c'est parfait pour mon attention gâchée.\"]\n",
            " > Processing time: 0.5961291790008545\n",
            " > Real-time factor: 0.1716908097827696\n",
            " > Text splitted to sentences.\n",
            "['La barre latérale est empilée avec tout ce dont vous avez besoin.']\n",
            " > Processing time: 0.6738636493682861\n",
            " > Real-time factor: 0.17692290756061524\n",
            " > Text splitted to sentences.\n",
            "['Mais la vraie dopamine vient de GX mods, où vous pouvez installer des mods qui changent tout le navigateur.']\n",
            " > Processing time: 1.2015845775604248\n",
            " > Real-time factor: 0.21877840480254465\n",
            " > Text splitted to sentences.\n",
            "[\"Vous pouvez télécharger des fonds d'écran animés, couleurs thématiques, musique de fond,\"]\n",
            " > Processing time: 1.4263665676116943\n",
            " > Real-time factor: 0.2876791198580223\n",
            " > Text splitted to sentences.\n",
            "['et les effets sonores absolus du changeur de jeu.']\n",
            " > Processing time: 0.9036431312561035\n",
            " > Real-time factor: 0.28399844703815685\n",
            " > Text splitted to sentences.\n",
            "['Il y a aussi une quantité ridicule de mods communautaires que vous pouvez choisir,']\n",
            " > Processing time: 1.2932021617889404\n",
            " > Real-time factor: 0.28629626172134676\n",
            " > Text splitted to sentences.\n",
            "['Donc ça devient assez fou.']\n",
            " > Processing time: 0.6011245250701904\n",
            " > Real-time factor: 0.27385941689664667\n",
            " > Text splitted to sentences.\n",
            "['Et pour la cerise sur le dessus, en utilisant GX Control, vous pouvez limiter la quantité de RAM,']\n",
            " > Processing time: 1.7521939277648926\n",
            " > Real-time factor: 0.30986042046721324\n",
            " > Text splitted to sentences.\n",
            "['utilisation du réseau et du processeur OperaGX utilise.']\n",
            " > Processing time: 1.1316344738006592\n",
            " > Real-time factor: 0.28832201131568375\n",
            " > Text splitted to sentences.\n",
            "[\"Tu sais, juste pour t'assurer que tu es très important 50 onglets, ne ralentis pas ton PC.\"]\n",
            "tu sais, juste pour t'assurer que tu es très important 50 onglets, ne ralentis pas ton pc.\n",
            " [!] Character '0' not found in the vocabulary. Discarding it.\n",
            " > Processing time: 1.6462557315826416\n",
            " > Real-time factor: 0.29232652752059374\n",
            " > Text splitted to sentences.\n",
            "['Vous pouvez utiliser mon lien ci-dessous pour télécharger OperaGX.']\n",
            " > Processing time: 1.0246493816375732\n",
            " > Real-time factor: 0.2864871026717956\n",
            " > Text splitted to sentences.\n",
            "[\"Et seulement avec mon lien, si vous allez au coin GX, vous pouvez voir mes 12 dernières vidéos que j'ai téléchargées.\"]\n",
            "et seulement avec mon lien, si vous allez au coin gx, vous pouvez voir mes 12 dernières vidéos que j'ai téléchargées.\n",
            " [!] Character '2' not found in the vocabulary. Discarding it.\n",
            " > Processing time: 1.8333196640014648\n",
            " > Real-time factor: 0.3007432046127864\n",
            " > Text splitted to sentences.\n",
            "['Il est en fait rempli de tant de fonctionnalités.']\n",
            " > Processing time: 0.5084421634674072\n",
            " > Real-time factor: 0.170361501708855\n",
            " > Text splitted to sentences.\n",
            "['Merci, OperaGX.']\n",
            " > Processing time: 0.35923314094543457\n",
            " > Real-time factor: 0.17088994558696136\n",
            " > Text splitted to sentences.\n",
            "[\"Voilà le problème que j'ai eu.\"]\n",
            " > Processing time: 0.38129734992980957\n",
            " > Real-time factor: 0.16665886786299358\n",
            " > Text splitted to sentences.\n",
            "[\"Reconstruire tous les Times Square à partir d'un projet vide non seulement semble complètement impossible pour moi,\"]\n",
            " > Processing time: 1.1767616271972656\n",
            " > Real-time factor: 0.19014241030381424\n",
            " > Text splitted to sentences.\n",
            "['Ça ressemble aussi à de la torture.']\n",
            " > Processing time: 0.5215516090393066\n",
            " > Real-time factor: 0.20888210148424716\n",
            " > Text splitted to sentences.\n",
            "[\"Mais je ne veux pas non plus acheter un modèle 3D du travail acharné de quelqu'un d'autre.\"]\n",
            "mais je ne veux pas non plus acheter un modèle 3d du travail acharné de quelqu'un d'autre.\n",
            " [!] Character '3' not found in the vocabulary. Discarding it.\n",
            " > Processing time: 1.302288293838501\n",
            " > Real-time factor: 0.28537383605440997\n",
            " > Text splitted to sentences.\n",
            "[\"J'ai donc acheté un modèle 3D du travail acharné de quelqu'un d'autre.\"]\n",
            " > Processing time: 1.1497294902801514\n",
            " > Real-time factor: 0.2912095118162716\n",
            " > Text splitted to sentences.\n",
            "[\"Pour le prix de 60 $, j'ai la parfaite récréation individuelle de Times Square.\"]\n",
            "pour le prix de 60 $, j'ai la parfaite récréation individuelle de times square.\n",
            " [!] Character '6' not found in the vocabulary. Discarding it.\n",
            "pour le prix de 60 $, j'ai la parfaite récréation individuelle de times square.\n",
            " [!] Character '$' not found in the vocabulary. Discarding it.\n",
            " > Processing time: 1.3696889877319336\n",
            " > Real-time factor: 0.2884037641280475\n",
            " > Text splitted to sentences.\n",
            "[\"Il n'y a qu'un problème.\"]\n",
            " > Processing time: 0.5333821773529053\n",
            " > Real-time factor: 0.2800256431102753\n",
            " > Text splitted to sentences.\n",
            "['Ça ressemble à ça.']\n",
            " > Processing time: 0.4064791202545166\n",
            " > Real-time factor: 0.26511076081436613\n",
            " > Text splitted to sentences.\n",
            "[\"Je veux dire, ce n'est même pas proche.\"]\n",
            " > Processing time: 0.6507987976074219\n",
            " > Real-time factor: 0.26684977475534905\n",
            " > Text splitted to sentences.\n",
            "[\"Merci Franco comme Jean, mais je ne dirais pas que ça a l'air réaliste.\"]\n",
            " > Processing time: 1.2458765506744385\n",
            " > Real-time factor: 0.2939519981849359\n",
            " > Text splitted to sentences.\n",
            "['Ces personnages de Roblox doivent partir, et je dois supprimer toutes les textures.']\n",
            " > Processing time: 1.4674627780914307\n",
            " > Real-time factor: 0.2939030869142934\n",
            " > Text splitted to sentences.\n",
            "[\"Et maintenant, c'est comme la toile blanche parfaite à transformer.\"]\n",
            " > Processing time: 1.1132960319519043\n",
            " > Real-time factor: 0.2844912097225511\n",
            " > Text splitted to sentences.\n",
            "[\"Mais c'est comme si j'avais acheté la coquille d'une voiture.\"]\n",
            " > Processing time: 1.024998664855957\n",
            " > Real-time factor: 0.29035483761657055\n",
            " > Text splitted to sentences.\n",
            "['Et maintenant je dois tout mettre ensemble.']\n",
            " > Processing time: 0.7375180721282959\n",
            " > Real-time factor: 0.28225273344954394\n",
            " > Text splitted to sentences.\n",
            "[\"Ce n'était pas facile et il a fallu 7 jours pour remasteriser Times Square avec Rockstar Level Quality.\"]\n",
            "ce n'était pas facile et il a fallu 7 jours pour remasteriser times square avec rockstar level quality.\n",
            " [!] Character '7' not found in the vocabulary. Discarding it.\n",
            " > Processing time: 1.7053403854370117\n",
            " > Real-time factor: 0.2914038708841143\n",
            " > Text splitted to sentences.\n",
            "['Oui!']\n",
            " > Processing time: 0.34473252296447754\n",
            " > Real-time factor: 0.24128212707487082\n",
            " > Text splitted to sentences.\n",
            "[\"Mec, c'est mon meilleur travail.\"]\n",
            " > Processing time: 0.6439974308013916\n",
            " > Real-time factor: 0.26406098164926145\n",
            " > Text splitted to sentences.\n",
            "['Je suis tellement excitée, et ça va encore mieux.']\n",
            " > Processing time: 0.5842657089233398\n",
            " > Real-time factor: 0.17715977560175528\n",
            " > Text splitted to sentences.\n",
            "[\"Laissez-moi vous montrer comment j'ai fait avant qu'on ne se balade vraiment.\"]\n",
            " > Processing time: 0.7657754421234131\n",
            " > Real-time factor: 0.20353602337055518\n",
            " > Text splitted to sentences.\n",
            "[\"L'une des choses qui vend le réalisme le plus est le terrain.\"]\n",
            " > Processing time: 0.5995862483978271\n",
            " > Real-time factor: 0.17743285346215495\n",
            " > Text splitted to sentences.\n",
            "['Regarde ça, frérot.']\n",
            " > Processing time: 0.39277052879333496\n",
            " > Real-time factor: 0.16742557531497518\n",
            " > Text splitted to sentences.\n",
            "[\"Je ne pouvais pas m'en sortir avec juste une texture d'asphalte lisse.\"]\n",
            " > Processing time: 0.7275540828704834\n",
            " > Real-time factor: 0.1759979762078085\n",
            " > Text splitted to sentences.\n",
            "['Ça aurait ruiné le réalisme.']\n",
            " > Processing time: 0.45650386810302734\n",
            " > Real-time factor: 0.17548658109609053\n",
            " > Text splitted to sentences.\n",
            "[\"Donc j'ai fini par faire ce matériau complexe mis en place avec cinq textures différentes\"]\n",
            " > Processing time: 1.4072659015655518\n",
            " > Real-time factor: 0.2595193791777099\n",
            " > Text splitted to sentences.\n",
            "['pour parvenir à cette voie réaliste.']\n",
            " > Processing time: 0.6933598518371582\n",
            " > Real-time factor: 0.2726209831135759\n",
            " > Text splitted to sentences.\n",
            "['Et je suis tellement fier de ça.']\n",
            " > Processing time: 0.5892794132232666\n",
            " > Real-time factor: 0.28188153118650267\n",
            " > Text splitted to sentences.\n",
            "[\"Et ne clown même pas cette animation en cours d'exécution.\"]\n",
            " > Processing time: 0.9463577270507812\n",
            " > Real-time factor: 0.27909249787970425\n",
            " > Text splitted to sentences.\n",
            "[\"Le GTA 4-1 a l'air aussi ridicule, et j'ai dû le copier pour être cohérent.\"]\n",
            " > Processing time: 1.2860841751098633\n",
            " > Real-time factor: 0.2825418067628376\n",
            " > Text splitted to sentences.\n",
            "['Tu vois ce que je veux dire?']\n",
            " > Processing time: 0.4729118347167969\n",
            " > Real-time factor: 0.26964485817918316\n",
            " > Text splitted to sentences.\n",
            "['Oui.']\n",
            " > Processing time: 0.2522544860839844\n",
            " > Real-time factor: 0.24672690818629592\n",
            " > Text splitted to sentences.\n",
            "[\"En plus de remplacer presque toutes les textures et d'ajouter de meilleurs modèles,\"]\n",
            " > Processing time: 1.424858808517456\n",
            " > Real-time factor: 0.28872717916308177\n",
            " > Text splitted to sentences.\n",
            "[\"C'était l'un de mes obstacles les plus frustrants à surmonter.\"]\n",
            " > Processing time: 0.9896619319915771\n",
            " > Real-time factor: 0.274036136231845\n",
            " > Text splitted to sentences.\n",
            "[\"J'ai dû recréer toutes les fausses annonces pour ces stupides panneaux d'affichage.\"]\n",
            " > Processing time: 1.2630815505981445\n",
            " > Real-time factor: 0.28776397122137015\n",
            " > Text splitted to sentences.\n",
            "['et doivent avoir des effets.']\n",
            " > Processing time: 0.525538444519043\n",
            " > Real-time factor: 0.2661733439370842\n",
            " > Text splitted to sentences.\n",
            "['Et ils avaient environ 50 ans.']\n",
            " > Processing time: 0.5201594829559326\n",
            " > Real-time factor: 0.26979480144849255\n",
            " > Text splitted to sentences.\n",
            "['Ne me demande même pas pourquoi je le sais.']\n",
            " > Processing time: 0.7673733234405518\n",
            " > Real-time factor: 0.2811848873614758\n",
            " > Text splitted to sentences.\n",
            "[\"Je pense qu'ils l'ont fait, je pense qu'ils l'ont fait.\"]\n",
            " > Processing time: 0.9428524971008301\n",
            " > Real-time factor: 0.30295374156378674\n",
            " > Text splitted to sentences.\n",
            "[\"Finalement, j'en ai eu tellement marre.\"]\n",
            " > Processing time: 0.7611205577850342\n",
            " > Real-time factor: 0.27082862605151053\n",
            " > Text splitted to sentences.\n",
            "[\"J'ai commencé à en générer quelques-uns.\"]\n",
            " > Processing time: 0.7216825485229492\n",
            " > Real-time factor: 0.27619238050074685\n",
            " > Text splitted to sentences.\n",
            "[\"Et c'est une bonne chose qu'ils soient à l'arrière.\"]\n",
            " > Processing time: 0.7979857921600342\n",
            " > Real-time factor: 0.2887172932057094\n",
            " > Text splitted to sentences.\n",
            "[\"Nous sommes si près d'un million, les gars.\"]\n",
            " > Processing time: 0.6994693279266357\n",
            " > Real-time factor: 0.2762843701773846\n",
            " > Text splitted to sentences.\n",
            "[\"Si vous voulez que Rockstar m'engage, abonnez-vous.\"]\n",
            " > Processing time: 0.7842917442321777\n",
            " > Real-time factor: 0.25777535416646075\n",
            " > Text splitted to sentences.\n",
            "['Je dois rapporter mon père.']\n",
            " > Processing time: 0.36876487731933594\n",
            " > Real-time factor: 0.1804061400623748\n",
            " > Text splitted to sentences.\n",
            "['Nous sommes sur le point de frapper une millième.']\n",
            " > Processing time: 0.4267539978027344\n",
            " > Real-time factor: 0.18373019469599916\n",
            " > Text splitted to sentences.\n",
            "['Oui, monsieur.']\n",
            " > Processing time: 0.2260284423828125\n",
            " > Real-time factor: 0.16630830067208408\n",
            " > Text splitted to sentences.\n",
            "['Oui, monsieur.']\n",
            " > Processing time: 0.2112736701965332\n",
            " > Real-time factor: 0.15815400691993337\n",
            " > Text splitted to sentences.\n",
            "['Toutes ces personnes qui marchent autour est un grand point de vente du jeu original']\n",
            " > Processing time: 0.762763500213623\n",
            " > Real-time factor: 0.17563633228603165\n",
            " > Text splitted to sentences.\n",
            "['où il y avait cinq personnes à regarder.']\n",
            " > Processing time: 0.4316239356994629\n",
            " > Real-time factor: 0.18129586601213726\n",
            " > Text splitted to sentences.\n",
            "[\"N'essayez pas d'interagir avec eux.\"]\n",
            " > Processing time: 0.40120673179626465\n",
            " > Real-time factor: 0.16608982494945243\n",
            " > Text splitted to sentences.\n",
            "[\"Ils sont dans les unités d'affichage.\"]\n",
            " > Processing time: 0.40631556510925293\n",
            " > Real-time factor: 0.17150187998964447\n",
            " > Text splitted to sentences.\n",
            "[\"Rockstar m'a fait battre.\"]\n",
            " > Processing time: 0.3119175434112549\n",
            " > Real-time factor: 0.16890426896410043\n",
            " > Text splitted to sentences.\n",
            "['Tu es un faux et une escroquerie.']\n",
            " > Processing time: 0.6100690364837646\n",
            " > Real-time factor: 0.2626527306792215\n",
            " > Text splitted to sentences.\n",
            "[\"Mais j'ai fait un pas de plus en ajoutant les Avengers.\"]\n",
            " > Processing time: 0.923154354095459\n",
            " > Real-time factor: 0.2880285474842211\n",
            " > Text splitted to sentences.\n",
            "[\"Parce que tu sais, quand j'explorais Times Square, j'ai rencontré mon idole.\"]\n",
            " > Processing time: 1.277848482131958\n",
            " > Real-time factor: 0.2873282655307725\n",
            " > Text splitted to sentences.\n",
            "['Je viens de rencontrer Spider-Man.']\n",
            " > Processing time: 0.6691644191741943\n",
            " > Real-time factor: 0.29854069769324587\n",
            " > Text splitted to sentences.\n",
            "[\"Oh, tu sais, j'ai dû le doubler.\"]\n",
            " > Processing time: 0.6030673980712891\n",
            " > Real-time factor: 0.27768201068058646\n",
            " > Text splitted to sentences.\n",
            "[\"Et si ça ne suffisait pas à Rockstar pour m'engager,\"]\n",
            " > Processing time: 1.0485849380493164\n",
            " > Real-time factor: 0.28849692907750335\n",
            " > Text splitted to sentences.\n",
            "[\"J'ai toujours la Statue de la Liberté dans ma dernière quête.\"]\n",
            " > Processing time: 0.9757611751556396\n",
            " > Real-time factor: 0.2937996219164007\n",
            " > Text splitted to sentences.\n",
            "[\"C'est là que je vais demain.\"]\n",
            " > Processing time: 0.49992942810058594\n",
            " > Real-time factor: 0.28132512989020825\n",
            " > Text splitted to sentences.\n",
            "[\"Après mon réveil dans ma chambre d'hôtel hantée,\"]\n",
            " > Processing time: 0.8471062183380127\n",
            " > Real-time factor: 0.27526957254116335\n",
            " > Text splitted to sentences.\n",
            "['Ça donne des vibrations de Cody.']\n",
            " > Processing time: 0.6040253639221191\n",
            " > Real-time factor: 0.2708826731712237\n",
            " > Text splitted to sentences.\n",
            "[\"J'ai quitté ma belle chambre d'hôtel pour commencer ma promenade à vélo de 5 miles pour arriver au ferryboat.\"]\n",
            " > Processing time: 1.5473172664642334\n",
            " > Real-time factor: 0.3021675794028655\n",
            " > Text splitted to sentences.\n",
            "['Au fait, tout au long de ce voyage, je fais du vélo à environ 75 miles.']\n",
            " > Processing time: 1.8003885746002197\n",
            " > Real-time factor: 0.39452385186371886\n",
            " > Text splitted to sentences.\n",
            "['Dis-lui de sortir le cappuccino.']\n",
            " > Processing time: 0.6450457572937012\n",
            " > Real-time factor: 0.2763300230868455\n",
            " > Text splitted to sentences.\n",
            "[\"C'est certainement le plus d'exercice que j'ai jamais eu de ma vie.\"]\n",
            " > Processing time: 0.9929244518280029\n",
            " > Real-time factor: 0.2888693287260854\n",
            " > Text splitted to sentences.\n",
            "['New York est en fait une telle ambiance.']\n",
            " > Processing time: 0.8145406246185303\n",
            " > Real-time factor: 0.2794470496147404\n",
            " > Text splitted to sentences.\n",
            "[\"J'ai tellement apprécié mon temps.\"]\n",
            " > Processing time: 0.6267144680023193\n",
            " > Real-time factor: 0.2855176450299822\n",
            " > Text splitted to sentences.\n",
            "['Je souhaite cela directement en explorant juste pour le plaisir, pas même plus de vidéo.']\n",
            " > Processing time: 1.464698314666748\n",
            " > Real-time factor: 0.2933494208545433\n",
            " > Text splitted to sentences.\n",
            "['Comme tout mon chemin vers la Statue de la Liberté,']\n",
            " > Processing time: 0.8062276840209961\n",
            " > Real-time factor: 0.27549777511565465\n",
            " > Text splitted to sentences.\n",
            "[\"J'ai trébuché sur ce mur de graffitis super malade.\"]\n",
            " > Processing time: 0.5823512077331543\n",
            " > Real-time factor: 0.18104055000163619\n",
            " > Text splitted to sentences.\n",
            "['Et je veux dire, tu ne pourrais jamais recréer ce niveau de détail.']\n",
            " > Processing time: 0.9064080715179443\n",
            " > Real-time factor: 0.22890665632410978\n",
            " > Text splitted to sentences.\n",
            "[\"Je voulais tant que ça dans notre remaster, alors j'ai photographié le mur sur mon téléphone.\"]\n",
            " > Processing time: 0.9531893730163574\n",
            " > Real-time factor: 0.1878470048174128\n",
            " > Text splitted to sentences.\n",
            "[\"Je n'ai même pas eu de vidéo.\"]\n",
            " > Processing time: 0.35030341148376465\n",
            " > Real-time factor: 0.17137447247109092\n",
            " > Text splitted to sentences.\n",
            "[\"Mais c'est ce à quoi ça ressemble.\"]\n",
            " > Processing time: 0.3500936031341553\n",
            " > Real-time factor: 0.17424078975054452\n",
            " > Text splitted to sentences.\n",
            "[\"Tu marches autour de l'objet, tu cherches des détails,\"]\n",
            " > Processing time: 0.6139700412750244\n",
            " > Real-time factor: 0.17682914590013438\n",
            " > Text splitted to sentences.\n",
            "['Ce qui se transforme en ceci.']\n",
            " > Processing time: 0.6107742786407471\n",
            " > Real-time factor: 0.2889541032446891\n",
            " > Text splitted to sentences.\n",
            "[\"C'est comme de la magie.\"]\n",
            " > Processing time: 0.4434967041015625\n",
            " > Real-time factor: 0.27469388554605206\n",
            " > Text splitted to sentences.\n",
            "['Vous obtenez un modèle en 3D de ce que vous avez capturé.']\n",
            " > Processing time: 0.870558500289917\n",
            " > Real-time factor: 0.2951386059562219\n",
            " > Text splitted to sentences.\n",
            "[\"Et après un peu de sauce, je l'ai ajouté dans ma version de GTA 4.\"]\n",
            " > Processing time: 1.1858057975769043\n",
            " > Real-time factor: 0.2926031539455096\n",
            " > Text splitted to sentences.\n",
            "[\"En fait, c'est trop cool.\"]\n",
            " > Processing time: 0.5326392650604248\n",
            " > Real-time factor: 0.27963561415672306\n",
            " > Text splitted to sentences.\n",
            "['Ton garçon avait vraiment besoin de vacances,']\n",
            " > Processing time: 0.9159107208251953\n",
            " > Real-time factor: 0.28371307308096705\n",
            " > Text splitted to sentences.\n",
            "[\"C'est donc une explosion absolue.\"]\n",
            " > Processing time: 0.7882533073425293\n",
            " > Real-time factor: 0.30033497074410376\n",
            " > Text splitted to sentences.\n",
            "['Ça a été un problème ici.']\n",
            " > Processing time: 0.733727216720581\n",
            " > Real-time factor: 0.2833196471120904\n",
            " > Text splitted to sentences.\n",
            "['Et je suis tellement reconnaissant pour vous les gars.']\n",
            " > Processing time: 0.8821144104003906\n",
            " > Real-time factor: 0.2899270025836008\n",
            " > Text splitted to sentences.\n",
            "[\"Mais la mission n'est jamais terminée et ce voyage allait s'améliorer encore.\"]\n",
            " > Processing time: 1.2496967315673828\n",
            " > Real-time factor: 0.29566322887404284\n",
            " > Text splitted to sentences.\n",
            "['Cette merde ressemble à un serveur GTA en ce moment.']\n",
            " > Processing time: 0.9377520084381104\n",
            " > Real-time factor: 0.2823551423702798\n",
            " > Text splitted to sentences.\n",
            "[\"La Statue de l'île de la Liberté.\"]\n",
            " > Processing time: 0.6810479164123535\n",
            " > Real-time factor: 0.29175292502510874\n",
            " > Text splitted to sentences.\n",
            "[\"Sur cette mission, je voulais me défier en modélisant toute l'île.\"]\n",
            " > Processing time: 1.1855056285858154\n",
            " > Real-time factor: 0.30384507055882964\n",
            " > Text splitted to sentences.\n",
            "['de zéro à la dimension exacte de la vie réelle.']\n",
            " > Processing time: 0.9462981224060059\n",
            " > Real-time factor: 0.28003373415090765\n",
            " > Text splitted to sentences.\n",
            "['Sauf pour la Statue de la Liberté.']\n",
            " > Processing time: 0.6508040428161621\n",
            " > Real-time factor: 0.28159790314160865\n",
            " > Text splitted to sentences.\n",
            "[\"C'est pas possible que tu m'aies fait mordre ça.\"]\n",
            " > Processing time: 0.7284324169158936\n",
            " > Real-time factor: 0.28905007905620955\n",
            " > Text splitted to sentences.\n",
            "[\"La bonne chose, c'est que l'île de la GTA 4 manquait en quelque sorte.\"]\n",
            " > Processing time: 1.1395263671875\n",
            " > Real-time factor: 0.3000974153984853\n",
            " > Text splitted to sentences.\n",
            "[\"Je veux dire, c'est plutôt ennuyeux,\"]\n",
            " > Processing time: 0.7494163513183594\n",
            " > Real-time factor: 0.2805730532900337\n",
            " > Text splitted to sentences.\n",
            "['Et la Statue de la Liberté ressemble à Hillary Clinton.']\n",
            " > Processing time: 0.9923059940338135\n",
            " > Real-time factor: 0.28868940215914063\n",
            " > Text splitted to sentences.\n",
            "['Je vais le donner à Rockstar.']\n",
            " > Processing time: 0.6519110202789307\n",
            " > Real-time factor: 0.28639301078160706\n",
            " > Text splitted to sentences.\n",
            "[\"Il y a un œuf d'est super cool qui est caché dans la Statue.\"]\n",
            " > Processing time: 1.1061124801635742\n",
            " > Real-time factor: 0.28434270877176376\n",
            " > Text splitted to sentences.\n",
            "[\"Et ça s'appelle le cœur de la ville de la liberté.\"]\n",
            " > Processing time: 0.8249545097351074\n",
            " > Real-time factor: 0.29113711491131755\n",
            " > Text splitted to sentences.\n",
            "['Et je vais recréer ça aussi.']\n",
            " > Processing time: 0.5397753715515137\n",
            " > Real-time factor: 0.2833820700645447\n",
            " > Text splitted to sentences.\n",
            "[\"Ne t'inquiète pas.\"]\n",
            " > Processing time: 0.4511227607727051\n",
            " > Real-time factor: 0.26786021313652914\n",
            " > Text splitted to sentences.\n",
            "[\"Au fait, j'ai oublié ces choses.\"]\n",
            " > Processing time: 0.4641580581665039\n",
            " > Real-time factor: 0.180850388439557\n",
            " > Text splitted to sentences.\n",
            "['Donc la vidéo ne dure pas 20 minutes.']\n",
            " > Processing time: 0.4919605255126953\n",
            " > Real-time factor: 0.17799503786352933\n",
            " > Text splitted to sentences.\n",
            "[\"Et c'est un peu douloureux.\"]\n",
            " > Processing time: 0.3327782154083252\n",
            " > Real-time factor: 0.18366438851005132\n",
            " > Text splitted to sentences.\n",
            "['Mais cela a pris cinq jours de broyage direct pour être complet.']\n",
            " > Processing time: 0.7069594860076904\n",
            " > Real-time factor: 0.17801544704080913\n",
            " > Text splitted to sentences.\n",
            "['Ça valait le coup?']\n",
            " > Processing time: 0.2425248622894287\n",
            " > Real-time factor: 0.1725501165940211\n",
            " > Text splitted to sentences.\n",
            "[\"J'ai pu transformer ça en ça.\"]\n",
            " > Processing time: 0.40981531143188477\n",
            " > Real-time factor: 0.17047290252552558\n",
            " > Text splitted to sentences.\n",
            "[\"Ça a l'air tellement photoréaliste.\"]\n",
            " > Processing time: 0.45105552673339844\n",
            " > Real-time factor: 0.18064832832881858\n",
            " > Text splitted to sentences.\n",
            "['Dites-moi ce que vous pensez après avoir vu ces prochains clips.']\n",
            " > Processing time: 0.6797258853912354\n",
            " > Real-time factor: 0.17955668694744034\n",
            " > Text splitted to sentences.\n",
            "['Les arbres photoréalistes et les gens qui se promènent']\n",
            " > Processing time: 0.9365789890289307\n",
            " > Real-time factor: 0.2839874409803069\n",
            " > Text splitted to sentences.\n",
            "[\"C'est ce qui me l'apporte vraiment.\"]\n",
            " > Processing time: 0.5272648334503174\n",
            " > Real-time factor: 0.2873218064842699\n",
            " > Text splitted to sentences.\n",
            "[\"Ça fait qu'il se sent tellement plus vivant.\"]\n",
            " > Processing time: 0.7178668975830078\n",
            " > Real-time factor: 0.3044968661839282\n",
            " > Text splitted to sentences.\n",
            "['Et se balader dans la vraie vie et prendre beaucoup de photos']\n",
            " > Processing time: 1.0149261951446533\n",
            " > Real-time factor: 0.28750157506345847\n",
            " > Text splitted to sentences.\n",
            "[\"Ça m'a vraiment aidé à capturer tous les petits détails.\"]\n",
            " > Processing time: 1.380936861038208\n",
            " > Real-time factor: 0.4143487070799653\n",
            " > Text splitted to sentences.\n",
            "['Comme, par exemple, ce petit magasin était caché derrière ces arbres.']\n",
            " > Processing time: 1.4597301483154297\n",
            " > Real-time factor: 0.34822409739435717\n",
            " > Text splitted to sentences.\n",
            "[\"Je n'aurais jamais pensé l'ajouter.\"]\n",
            " > Processing time: 0.7949943542480469\n",
            " > Real-time factor: 0.3125824805843337\n",
            " > Text splitted to sentences.\n",
            "[\"Je l'admets, mais je l'ai seulement modelé pour être vu de loin,\"]\n",
            " > Processing time: 1.2542221546173096\n",
            " > Real-time factor: 0.33752683203123995\n",
            " > Text splitted to sentences.\n",
            "[\"Alors ne t'approche pas.\"]\n",
            " > Processing time: 0.5203349590301514\n",
            " > Real-time factor: 0.28000258313683224\n",
            " > Text splitted to sentences.\n",
            "['Mais quelque chose que je voulais que tu voies de près']\n",
            " > Processing time: 0.891920804977417\n",
            " > Real-time factor: 0.29092978919751544\n",
            " > Text splitted to sentences.\n",
            "['est le cœur de la ville de la liberté,']\n",
            " > Processing time: 0.6672840118408203\n",
            " > Real-time factor: 0.2749180205734321\n",
            " > Text splitted to sentences.\n",
            "[\"qui est l'œuf de l'est situé à l'intérieur de la Statue.\"]\n",
            " > Processing time: 0.8626983165740967\n",
            " > Real-time factor: 0.2792826209839504\n",
            " > Text splitted to sentences.\n",
            "[\"J'ai peut-être été un peu trop fou.\"]\n",
            " > Processing time: 0.6701023578643799\n",
            " > Real-time factor: 0.27346307726735225\n",
            " > Text splitted to sentences.\n",
            "[\"Ça ressemble à un film d'horreur ou quelque chose comme ça,\"]\n",
            " > Processing time: 0.9162752628326416\n",
            " > Real-time factor: 0.292233706686238\n",
            " > Text splitted to sentences.\n",
            "[\"Mais c'est un peu malade.\"]\n",
            " > Processing time: 0.47011852264404297\n",
            " > Real-time factor: 0.28503391509846976\n",
            " > Text splitted to sentences.\n",
            "[\"Rockstar, comme toujours, ce n'est qu'un concept.\"]\n",
            " > Processing time: 0.967456579208374\n",
            " > Real-time factor: 0.2740546964484153\n",
            " > Text splitted to sentences.\n",
            "[\"Ce n'est pas un jeu jouable.\"]\n",
            " > Processing time: 0.5476043224334717\n",
            " > Real-time factor: 0.2757278797419175\n",
            " > Text splitted to sentences.\n",
            "[\"Je n'ai rien donné, d'accord?\"]\n",
            " > Processing time: 0.686915397644043\n",
            " > Real-time factor: 0.27639570288414506\n",
            " > Text splitted to sentences.\n",
            "['Et même si je pouvais, ce clip de 10 secondes que vous regardez']\n",
            " > Processing time: 1.0982568264007568\n",
            " > Real-time factor: 0.2798179310193276\n",
            " > Text splitted to sentences.\n",
            "['Il a fallu huit heures pour le rendre.']\n",
            " > Processing time: 0.6847290992736816\n",
            " > Real-time factor: 0.27296566095937014\n",
            " > Text splitted to sentences.\n",
            "[\"Sur un 49D, c'est plutôt fou.\"]\n",
            "sur un 49d, c'est plutôt fou.\n",
            " [!] Character '9' not found in the vocabulary. Discarding it.\n",
            " > Processing time: 0.6245033740997314\n",
            " > Real-time factor: 0.27717993959136633\n",
            " > Text splitted to sentences.\n",
            "[\"Les gars, est-ce que c'était un succès de mission?\"]\n",
            " > Processing time: 0.9445850849151611\n",
            " > Real-time factor: 0.2915467682303934\n",
            " > Text splitted to sentences.\n",
            "['Vous allez devoir me le dire.']\n",
            " > Processing time: 0.5587782859802246\n",
            " > Real-time factor: 0.2898254894115533\n",
            " > Text splitted to sentences.\n",
            "[\"Certainement l'un de mes projets préférés,\"]\n",
            " > Processing time: 0.6934034824371338\n",
            " > Real-time factor: 0.2713992258544945\n",
            " > Text splitted to sentences.\n",
            "[\"J'espère que vous avez apprécié.\"]\n",
            " > Processing time: 0.39591383934020996\n",
            " > Real-time factor: 0.16629648273109626\n",
            "Moviepy - Building video /content/drive/MyDrive/Colab Notebooks/CS370_project/videos7/I Remastered GTA 4 (Sorry Rockstar)_translated.mp4.\n",
            "MoviePy - Writing audio in I Remastered GTA 4 (Sorry Rockstar)_translatedTEMP_MPY_wvf_snd.mp3\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MoviePy - Done.\n",
            "Moviepy - Writing video /content/drive/MyDrive/Colab Notebooks/CS370_project/videos7/I Remastered GTA 4 (Sorry Rockstar)_translated.mp4\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "t: 100%|██████████| 16730/16730 [25:08<00:00, 12.88it/s, now=None]WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/moviepy/video/io/ffmpeg_reader.py:123: UserWarning: Warning: in file /content/drive/MyDrive/Colab Notebooks/CS370_project/videos7/I Remastered GTA 4 (Sorry Rockstar).mp4, 2764800 bytes wanted but 0 bytes read,at frame 16729/16730, at time 557.63/557.65 sec. Using the last valid frame instead.\n",
            "  warnings.warn(\"Warning: in file %s, \"%(self.filename)+\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready /content/drive/MyDrive/Colab Notebooks/CS370_project/videos7/I Remastered GTA 4 (Sorry Rockstar)_translated.mp4\n",
            "Processed video saved at /content/drive/MyDrive/Colab Notebooks/CS370_project/videos7/I Remastered GTA 4 (Sorry Rockstar)_translated_subtitled.mp4\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import re\n",
        "import nltk\n",
        "from pytube import YouTube\n",
        "from transformers import MarianMTModel, MarianTokenizer\n",
        "from moviepy.editor import VideoFileClip, concatenate_audioclips, AudioFileClip\n",
        "from whisper import load_model\n",
        "from TTS.api import TTS\n",
        "from pydub import AudioSegment, silence\n",
        "import pysubs2\n",
        "import subprocess\n",
        "\n",
        "nltk.download('punkt')\n",
        "model_name = 'Helsinki-NLP/opus-mt-en-fr'\n",
        "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
        "model = MarianMTModel.from_pretrained(model_name)\n",
        "tts = TTS(model_name=\"tts_models/fr/css10/vits\")\n",
        "whisper_model = load_model(\"base\")\n",
        "\n",
        "\n",
        "save_path =  \"/content/drive/MyDrive/Colab Notebooks/CS370_project/videos7\"\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "audio_folder = os.path.join(save_path, \"audio\")\n",
        "os.makedirs(audio_folder, exist_ok=True)\n",
        "tts_audio_folder = os.path.join(save_path, \"tts_audio\")\n",
        "os.makedirs(tts_audio_folder, exist_ok=True)\n",
        "\n",
        "def cleaned_video(video_name):\n",
        "    return re.sub(r'[\\\\/*?:\"<>|]', \"\", video_name)\n",
        "\n",
        "def translate(text):\n",
        "    sentences = nltk.tokenize.sent_tokenize(text)\n",
        "    translations = []\n",
        "    for sentence in sentences:\n",
        "        batch = tokenizer(sentence, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "        gen = model.generate(**batch)\n",
        "        translation = tokenizer.batch_decode(gen, skip_special_tokens=True)\n",
        "        translations.append(translation[0])\n",
        "    return ' '.join(translations)\n",
        "\n",
        "def generate_tts_audio(text, start, end, tts_audio_path):\n",
        "    tts.tts_to_file(text=text, file_path=tts_audio_path)\n",
        "    tts_audio = AudioSegment.from_mp3(tts_audio_path)\n",
        "    expected_duration = (end - start) * 1000\n",
        "    actual_duration = len(tts_audio)\n",
        "    if actual_duration < expected_duration:\n",
        "        silence_duration = expected_duration - actual_duration\n",
        "        silence_audio = AudioSegment.silent(duration=silence_duration)\n",
        "        tts_audio += silence_audio\n",
        "        tts_audio.export(tts_audio_path, format='wav')\n",
        "    return True\n",
        "\n",
        "def create_subtitles(segments, subtitles_file):\n",
        "    subs = pysubs2.SSAFile()\n",
        "    for start, end, text in segments:\n",
        "        start_ms = int(start * 1000)\n",
        "        end_ms = int(end * 1000)\n",
        "        subs.append(pysubs2.SSAEvent(start=start_ms, end=end_ms, text=text))\n",
        "    subs.save(subtitles_file)\n",
        "\n",
        "def embed_subtitles(video_path, subtitles_path, output_path):\n",
        "    command = [\n",
        "        'ffmpeg',\n",
        "        '-i', video_path,\n",
        "        '-vf', f\"subtitles={subtitles_path}\",\n",
        "        '-c:a', 'copy',\n",
        "        output_path\n",
        "    ]\n",
        "    subprocess.run(command, check=True)\n",
        "\n",
        "def process_video(url):\n",
        "    yt = YouTube(url)\n",
        "    video_id = yt.video_id\n",
        "    yt_title_cleaned = cleaned_video(yt.title)\n",
        "    video_stream = yt.streams.filter(progressive=True, file_extension='mp4').order_by('resolution').desc().first()\n",
        "\n",
        "    if not video_stream:\n",
        "        print(\"No suitable video stream found.\")\n",
        "        return None\n",
        "\n",
        "    video_path = os.path.join(save_path, yt_title_cleaned + \".mp4\")\n",
        "    video_stream.download(output_path=save_path, filename=yt_title_cleaned + \".mp4\")\n",
        "\n",
        "    video_clip = VideoFileClip(video_path)\n",
        "    audio_path = os.path.join(audio_folder, yt_title_cleaned + \".mp3\")\n",
        "    video_clip.audio.write_audiofile(audio_path)\n",
        "\n",
        "    result = whisper_model.transcribe(audio_path)\n",
        "    segments = []\n",
        "    for segment in result[\"segments\"]:\n",
        "        start_time, end_time, text = segment[\"start\"], segment[\"end\"], segment[\"text\"]\n",
        "        segments.append((start_time, end_time, text))\n",
        "\n",
        "    translated_segments = []\n",
        "    tts_clips = []\n",
        "    for start, end, text in segments:\n",
        "        translated_text = translate(text)\n",
        "        translated_segments.append((start, end, translated_text))\n",
        "\n",
        "        tts_audio_path = os.path.join(tts_audio_folder, f\"tts_{start}_{end}.wav\")\n",
        "        generate_tts_audio(translated_text, start, end, tts_audio_path)\n",
        "\n",
        "        tts_clip = AudioFileClip(tts_audio_path).subclip(0, end - start)\n",
        "        tts_clips.append(tts_clip)\n",
        "\n",
        "    combined_tts_audio = concatenate_audioclips(tts_clips)\n",
        "    final_video = video_clip.set_audio(combined_tts_audio)\n",
        "    final_video_path = os.path.join(save_path, yt_title_cleaned + \"_translated.mp4\")\n",
        "    final_video.write_videofile(final_video_path)\n",
        "\n",
        "    subtitles_file = os.path.join(save_path, yt_title_cleaned + \".srt\")\n",
        "    create_subtitles(translated_segments, subtitles_file)\n",
        "\n",
        "    embedded_video_path = os.path.join(save_path, yt_title_cleaned + \"_translated_subtitled.mp4\")\n",
        "    embed_subtitles(final_video_path, subtitles_file, embedded_video_path)\n",
        "\n",
        "    return embedded_video_path\n",
        "\n",
        "#url1 = 'https://youtu.be/CSoXyDcUxEk?si=kwNDyTE-hIy6jpi6'\n",
        "url2 = \"https://youtu.be/8aahBio9Xqs?si=i4wYi1t3qYDR4D4Y\"\n",
        "#processed_video_path = process_video(url1)\n",
        "processed_video_path = process_video(url2)\n",
        "if processed_video_path:\n",
        "    print(f\"Processed video saved at {processed_video_path}\")\n",
        "else:\n",
        "    print(\"Failed to process video.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt update && sudo apt install ffmpeg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ey2g4OujKmPf",
        "outputId": "4b75fc4c-4fab-4242-bb98-8429a53e901b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "\u001b[33m\r0% [Waiting for headers] [Waiting for headers] [1 InRelease 3,626 B/3,626 B 100\u001b[0m\u001b[33m\r0% [Waiting for headers] [Waiting for headers] [Waiting for headers] [Waiting f\u001b[0m\r                                                                               \rGet:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "\u001b[33m\r0% [Waiting for headers] [Waiting for headers] [Waiting for headers] [2 InRelea\u001b[0m\u001b[33m\r                                                                               \r0% [Waiting for headers] [Waiting for headers] [Waiting for headers]\u001b[0m\r                                                                    \rHit:3 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "\u001b[33m\r                                                                    \r0% [Waiting for headers] [Waiting for headers]\u001b[0m\r                                              \rGet:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "\u001b[33m\r0% [Waiting for headers] [4 InRelease 12.7 kB/110 kB 12%] [Waiting for headers]\u001b[0m\r                                                                               \rHit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "\u001b[33m\r                                                                               \r0% [4 InRelease 14.2 kB/110 kB 13%] [Waiting for headers]\u001b[0m\r                                                         \rHit:6 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "\u001b[33m\r0% [Waiting for headers] [4 InRelease 14.2 kB/110 kB 13%]\u001b[0m\r                                                         \rHit:7 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Hit:10 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Get:11 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [633 kB]\n",
            "Get:12 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,277 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,302 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,031 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [1,512 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,550 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [1,538 kB]\n",
            "Fetched 9,077 kB in 5s (1,667 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "15 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 15 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ffmpeg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhEjCfrXLK12",
        "outputId": "e7817d2b-0215-44e5-85fa-0a7045308334"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ffmpeg\n",
            "  Downloading ffmpeg-1.4.tar.gz (5.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: ffmpeg\n",
            "  Building wheel for ffmpeg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpeg: filename=ffmpeg-1.4-py3-none-any.whl size=6080 sha256=7d31883328ed54cfce761792fcf72de3d540c8e2ddedb17eacaac2f15c674018\n",
            "  Stored in directory: /root/.cache/pip/wheels/8e/7a/69/cd6aeb83b126a7f04cbe7c9d929028dc52a6e7d525ff56003a\n",
            "Successfully built ffmpeg\n",
            "Installing collected packages: ffmpeg\n",
            "Successfully installed ffmpeg-1.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/openai/whisper.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjpIkBthJ3K5",
        "outputId": "07064ba4-8aac-4147-fd6c-010aca399936"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-42066tln\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-42066tln\n",
            "  Resolved https://github.com/openai/whisper.git to commit e58f28804528831904c3b6f2c0e473f346223433\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: triton<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.1.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (0.58.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (1.22.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.1.0+cu118)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (4.66.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (10.1.0)\n",
            "Collecting tiktoken (from openai-whisper==20231117)\n",
            "  Downloading tiktoken-0.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton<3,>=2.0.0->openai-whisper==20231117) (3.13.1)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20231117) (0.41.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (2.8.8)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (2023.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper==20231117) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper==20231117) (1.3.0)\n",
            "Building wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20231117-py3-none-any.whl size=801356 sha256=d24f3ba834cc3ac90788ea2e872f41cded30da52dfb0910a1aed9bad704deca6\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-1foveonx/wheels/8b/6c/d0/622666868c179f156cf595c8b6f06f88bc5d80c4b31dccaa03\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: tiktoken, openai-whisper\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed openai-whisper-20231117 tiktoken-0.5.2\n"
          ]
        }
      ]
    }
  ]
}