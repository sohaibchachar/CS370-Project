{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7eNFgeUxEBav",
        "outputId": "33edc9ec-037f-47d6-bd4b-d340b374b4c3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytube transformers moviepy TTS youtube_transcript_api pydub SentencePiece pysubs2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nybTo9IuJOUI",
        "outputId": "66058f34-e923-49bd-a0af-7adf286dfa38"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytube in /usr/local/lib/python3.10/dist-packages (15.0.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.10/dist-packages (1.0.3)\n",
            "Requirement already satisfied: TTS in /usr/local/lib/python3.10/dist-packages (0.21.3)\n",
            "Requirement already satisfied: youtube_transcript_api in /usr/local/lib/python3.10/dist-packages (0.6.1)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (0.25.1)\n",
            "Requirement already satisfied: SentencePiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n",
            "Collecting pysubs2\n",
            "  Downloading pysubs2-1.6.1-py3-none-any.whl (35 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.1.10)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.31.6)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.4.9)\n",
            "Requirement already satisfied: cython>=0.29.30 in /usr/local/lib/python3.10/dist-packages (from TTS) (3.0.6)\n",
            "Requirement already satisfied: scipy>=1.11.2 in /usr/local/lib/python3.10/dist-packages (from TTS) (1.11.4)\n",
            "Requirement already satisfied: torch>=2.1 in /usr/local/lib/python3.10/dist-packages (from TTS) (2.1.0+cu118)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (from TTS) (2.1.0+cu118)\n",
            "Requirement already satisfied: soundfile>=0.12.0 in /usr/local/lib/python3.10/dist-packages (from TTS) (0.12.1)\n",
            "Requirement already satisfied: librosa>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from TTS) (0.10.0)\n",
            "Requirement already satisfied: scikit-learn>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from TTS) (1.3.2)\n",
            "Requirement already satisfied: inflect>=5.6.0 in /usr/local/lib/python3.10/dist-packages (from TTS) (7.0.0)\n",
            "Requirement already satisfied: anyascii>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from TTS) (0.3.2)\n",
            "Requirement already satisfied: fsspec>=2023.6.0 in /usr/local/lib/python3.10/dist-packages (from TTS) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from TTS) (3.9.1)\n",
            "Requirement already satisfied: flask>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from TTS) (2.2.5)\n",
            "Requirement already satisfied: pysbd>=0.3.4 in /usr/local/lib/python3.10/dist-packages (from TTS) (0.3.4)\n",
            "Requirement already satisfied: umap-learn>=0.5.1 in /usr/local/lib/python3.10/dist-packages (from TTS) (0.5.5)\n",
            "Requirement already satisfied: pandas<2.0,>=1.4 in /usr/local/lib/python3.10/dist-packages (from TTS) (1.5.3)\n",
            "Requirement already satisfied: matplotlib>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from TTS) (3.7.1)\n",
            "Requirement already satisfied: trainer>=0.0.32 in /usr/local/lib/python3.10/dist-packages (from TTS) (0.0.32)\n",
            "Requirement already satisfied: coqpit>=0.0.16 in /usr/local/lib/python3.10/dist-packages (from TTS) (0.0.17)\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.10/dist-packages (from TTS) (0.42.1)\n",
            "Requirement already satisfied: pypinyin in /usr/local/lib/python3.10/dist-packages (from TTS) (0.49.0)\n",
            "Requirement already satisfied: hangul-romanize in /usr/local/lib/python3.10/dist-packages (from TTS) (0.1.0)\n",
            "Requirement already satisfied: gruut[de,es,fr]==2.2.3 in /usr/local/lib/python3.10/dist-packages (from TTS) (2.2.3)\n",
            "Requirement already satisfied: jamo in /usr/local/lib/python3.10/dist-packages (from TTS) (0.4.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from TTS) (3.8.1)\n",
            "Requirement already satisfied: g2pkk>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from TTS) (0.1.2)\n",
            "Requirement already satisfied: bangla in /usr/local/lib/python3.10/dist-packages (from TTS) (0.0.2)\n",
            "Requirement already satisfied: bnnumerizer in /usr/local/lib/python3.10/dist-packages (from TTS) (0.0.2)\n",
            "Requirement already satisfied: bnunicodenormalizer in /usr/local/lib/python3.10/dist-packages (from TTS) (0.1.6)\n",
            "Requirement already satisfied: einops>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from TTS) (0.7.0)\n",
            "Requirement already satisfied: encodec>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from TTS) (0.1.1)\n",
            "Requirement already satisfied: unidecode>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from TTS) (1.3.7)\n",
            "Requirement already satisfied: num2words in /usr/local/lib/python3.10/dist-packages (from TTS) (0.5.13)\n",
            "Requirement already satisfied: spacy[ja]>=3 in /usr/local/lib/python3.10/dist-packages (from TTS) (3.6.1)\n",
            "Requirement already satisfied: numba>=0.57.0 in /usr/local/lib/python3.10/dist-packages (from TTS) (0.58.1)\n",
            "Requirement already satisfied: Babel<3.0.0,>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from gruut[de,es,fr]==2.2.3->TTS) (2.13.1)\n",
            "Requirement already satisfied: dateparser~=1.1.0 in /usr/local/lib/python3.10/dist-packages (from gruut[de,es,fr]==2.2.3->TTS) (1.1.8)\n",
            "Requirement already satisfied: gruut-ipa<1.0,>=0.12.0 in /usr/local/lib/python3.10/dist-packages (from gruut[de,es,fr]==2.2.3->TTS) (0.13.0)\n",
            "Requirement already satisfied: gruut-lang-en~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from gruut[de,es,fr]==2.2.3->TTS) (2.0.0)\n",
            "Requirement already satisfied: jsonlines~=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gruut[de,es,fr]==2.2.3->TTS) (1.2.0)\n",
            "Requirement already satisfied: networkx<3.0.0,>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from gruut[de,es,fr]==2.2.3->TTS) (2.8.8)\n",
            "Requirement already satisfied: python-crfsuite~=0.9.7 in /usr/local/lib/python3.10/dist-packages (from gruut[de,es,fr]==2.2.3->TTS) (0.9.9)\n",
            "Requirement already satisfied: gruut-lang-de~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from gruut[de,es,fr]==2.2.3->TTS) (2.0.0)\n",
            "Requirement already satisfied: gruut-lang-es~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from gruut[de,es,fr]==2.2.3->TTS) (2.0.0)\n",
            "Requirement already satisfied: gruut-lang-fr~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from gruut[de,es,fr]==2.2.3->TTS) (2.0.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.1->TTS) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.1->TTS) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.1->TTS) (1.9.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.1->TTS) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.1->TTS) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.1->TTS) (4.0.3)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from flask>=2.0.1->TTS) (3.0.1)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from flask>=2.0.1->TTS) (3.1.2)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from flask>=2.0.1->TTS) (2.1.2)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from flask>=2.0.1->TTS) (8.1.7)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: pillow<10.1.0,>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio<3.0,>=2.5->moviepy) (9.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from imageio-ffmpeg>=0.2.0->moviepy) (67.7.2)\n",
            "Requirement already satisfied: pydantic>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from inflect>=5.6.0->TTS) (1.10.13)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->TTS) (3.0.1)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->TTS) (1.3.2)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->TTS) (1.8.0)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->TTS) (0.3.7)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->TTS) (0.3)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->TTS) (1.0.7)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->TTS) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->TTS) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->TTS) (4.45.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->TTS) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->TTS) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->TTS) (2.8.2)\n",
            "Requirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.10/dist-packages (from num2words->TTS) (0.6.2)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.57.0->TTS) (0.41.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.0,>=1.4->TTS) (2023.3.post1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.0->TTS) (3.2.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.0->TTS) (1.16.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy[ja]>=3->TTS) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy[ja]>=3->TTS) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy[ja]>=3->TTS) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy[ja]>=3->TTS) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy[ja]>=3->TTS) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy[ja]>=3->TTS) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy[ja]>=3->TTS) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy[ja]>=3->TTS) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy[ja]>=3->TTS) (2.0.10)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy[ja]>=3->TTS) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy[ja]>=3->TTS) (0.10.3)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy[ja]>=3->TTS) (6.4.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy[ja]>=3->TTS) (3.3.0)\n",
            "Requirement already satisfied: sudachipy!=0.6.1,>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from spacy[ja]>=3->TTS) (0.6.7)\n",
            "Requirement already satisfied: sudachidict-core>=20211220 in /usr/local/lib/python3.10/dist-packages (from spacy[ja]>=3->TTS) (20230927)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.1->TTS) (1.12)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1->TTS) (2.1.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from trainer>=0.0.32->TTS) (5.9.5)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from trainer>=0.0.32->TTS) (2.14.1)\n",
            "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.10/dist-packages (from umap-learn>=0.5.1->TTS) (0.5.11)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.0->TTS) (2.21)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.10/dist-packages (from dateparser~=1.1.0->gruut[de,es,fr]==2.2.3->TTS) (5.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->flask>=2.0.1->TTS) (2.1.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from jsonlines~=1.2.0->gruut[de,es,fr]==2.2.3->TTS) (1.16.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa>=0.10.0->TTS) (4.0.0)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy[ja]>=3->TTS) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy[ja]>=3->TTS) (0.1.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.1->TTS) (1.3.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer>=0.0.32->TTS) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer>=0.0.32->TTS) (1.59.3)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer>=0.0.32->TTS) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer>=0.0.32->TTS) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer>=0.0.32->TTS) (3.5.1)\n",
            "Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer>=0.0.32->TTS) (3.20.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer>=0.0.32->TTS) (0.7.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->trainer>=0.0.32->TTS) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->trainer>=0.0.32->TTS) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->trainer>=0.0.32->TTS) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard->trainer>=0.0.32->TTS) (1.3.1)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->trainer>=0.0.32->TTS) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard->trainer>=0.0.32->TTS) (3.2.2)\n",
            "Installing collected packages: pysubs2\n",
            "Successfully installed pysubs2-1.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7CadmpsIJA3v",
        "outputId": "348ae1e3-2f60-4b60-919b-0bff74884339"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/transformers/models/marian/tokenization_marian.py:197: UserWarning: Recommended: pip install sacremoses.\n",
            "  warnings.warn(\"Recommended: pip install sacremoses.\")\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " > tts_models/fr/css10/vits is already downloaded.\n",
            " > Using model: vits\n",
            " > Setting up Audio Processor...\n",
            " | > sample_rate:22050\n",
            " | > resample:False\n",
            " | > num_mels:80\n",
            " | > log_func:np.log10\n",
            " | > min_level_db:0\n",
            " | > frame_shift_ms:None\n",
            " | > frame_length_ms:None\n",
            " | > ref_level_db:None\n",
            " | > fft_size:1024\n",
            " | > power:None\n",
            " | > preemphasis:0.0\n",
            " | > griffin_lim_iters:None\n",
            " | > signal_norm:None\n",
            " | > symmetric_norm:None\n",
            " | > mel_fmin:0\n",
            " | > mel_fmax:None\n",
            " | > pitch_fmin:None\n",
            " | > pitch_fmax:None\n",
            " | > spec_gain:20.0\n",
            " | > stft_pad_mode:reflect\n",
            " | > max_norm:1.0\n",
            " | > clip_norm:True\n",
            " | > do_trim_silence:False\n",
            " | > trim_db:60\n",
            " | > do_sound_norm:False\n",
            " | > do_amp_to_db_linear:True\n",
            " | > do_amp_to_db_mel:True\n",
            " | > do_rms_norm:False\n",
            " | > db_level:None\n",
            " | > stats_path:None\n",
            " | > base:10\n",
            " | > hop_length:256\n",
            " | > win_length:1024\n",
            " > initialization of speaker-embedding layers.\n",
            " > initialization of language-embedding layers.\n",
            "MoviePy - Writing audio in /content/drive/MyDrive/Colab Notebooks/CS370_project/videos1/audio/Elon Musk OpenAI is lying when it says it is not using copyrighted data.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            " > Text splitted to sentences.\n",
            "[\"C'est une question de propriété intellectuelle intéressante, que je pense être en fait quelque chose que je peux dire en tant que quelqu'un qui est dans les affaires créatrices et journalistiques et quoi que ce soit, ou qui se soucie du droit d'auteur.\"]\n",
            " > Processing time: 2.005516290664673\n",
            " > Real-time factor: 0.1893957471439904\n",
            " > Text splitted to sentences.\n",
            "[\"Donc, l'une des choses à propos de la formation sur les données a été l'idée que vous n'allez pas vous former, ou ces choses ne sont pas formés sur les informations protégées par le droit d'auteur des gens.\"]\n",
            " > Processing time: 1.9664645195007324\n",
            " > Real-time factor: 0.20553916692733767\n",
            " > Text splitted to sentences.\n",
            "[\"Historiquement, c'était le concept.\"]\n",
            " > Processing time: 0.7079637050628662\n",
            " > Real-time factor: 0.28620195982392566\n",
            " > Text splitted to sentences.\n",
            "[\"Oui, c'est un énorme mensonge.\"]\n",
            " > Processing time: 0.7230620384216309\n",
            " > Real-time factor: 0.2895872919790206\n",
            " > Text splitted to sentences.\n",
            "['Répète ça?']\n",
            " > Processing time: 0.3013594150543213\n",
            " > Real-time factor: 0.25432390929071436\n",
            " > Text splitted to sentences.\n",
            "[\"Ou ceux-ci, ceux-ci, ceux-ci, ceux-ci, ils sont tous formés sur les données protégées par le droit d'auteur, évidemment.\"]\n",
            " > Processing time: 1.9375176429748535\n",
            " > Real-time factor: 0.2912140366151947\n",
            " > Text splitted to sentences.\n",
            "[\"Donc, vous pensez que c'est un mensonge quand, quand l'IA ouverte dit que ce n'est pas, aucun de ces gars disent qu'ils sont une formation sur les données copyrighted.\"]\n",
            " > Processing time: 2.443852424621582\n",
            " > Real-time factor: 0.2943741038966539\n",
            " > Text splitted to sentences.\n",
            "[\"C'est un mensonge.\"]\n",
            " > Processing time: 0.35060667991638184\n",
            " > Real-time factor: 0.24146918078948712\n",
            " > Text splitted to sentences.\n",
            "[\"C'est un mensonge.\"]\n",
            " > Processing time: 0.25647640228271484\n",
            " > Real-time factor: 0.17523874164395956\n",
            " > Text splitted to sentences.\n",
            "['Oui.']\n",
            " > Processing time: 0.15955400466918945\n",
            " > Real-time factor: 0.1634835410295366\n",
            " > Text splitted to sentences.\n",
            "[\"C'est un mensonge droit.\"]\n",
            " > Processing time: 0.31308603286743164\n",
            " > Real-time factor: 0.17851538644825374\n",
            " > Text splitted to sentences.\n",
            "['Très bien.']\n",
            " > Processing time: 0.17128372192382812\n",
            " > Real-time factor: 0.16201124178193246\n",
            " > Text splitted to sentences.\n",
            "['Absolument.']\n",
            " > Processing time: 0.24616217613220215\n",
            " > Real-time factor: 0.1842706404031456\n",
            " > Text splitted to sentences.\n",
            "[\"De toute évidence, il a été formé sur les données protégées par le droit d'auteur.\"]\n",
            " > Processing time: 0.8839225769042969\n",
            " > Real-time factor: 0.1852145052905936\n",
            " > Text splitted to sentences.\n",
            "['Ok, donc la prochaine question.']\n",
            " > Processing time: 0.4786713123321533\n",
            " > Real-time factor: 0.18157690677339633\n",
            " > Text splitted to sentences.\n",
            "['La deuxième question.']\n",
            " > Processing time: 0.31431102752685547\n",
            " > Real-time factor: 0.18284503368950936\n",
            " > Text splitted to sentences.\n",
            "[\"C'est-à-dire, toutes les personnes qui ont téléchargé.\"]\n",
            " > Processing time: 0.6337475776672363\n",
            " > Real-time factor: 0.1862621839353082\n",
            " > Text splitted to sentences.\n",
            "[\"C'est comme un tout un chacun de ceux-là.\"]\n",
            " > Processing time: 0.5634558200836182\n",
            " > Real-time factor: 0.24137785267414869\n",
            " > Text splitted to sentences.\n",
            "['Toutes les personnes qui ont téléchargé.']\n",
            " > Processing time: 0.7071869373321533\n",
            " > Real-time factor: 0.2832292932318726\n",
            " > Text splitted to sentences.\n",
            "['Les articles, les meilleures citations de différents articles.']\n",
            " > Processing time: 1.1299004554748535\n",
            " > Real-time factor: 0.2887342972744822\n",
            " > Text splitted to sentences.\n",
            "['Des vidéos.']\n",
            " > Processing time: 0.2551078796386719\n",
            " > Real-time factor: 0.2412975611716161\n",
            " > Text splitted to sentences.\n",
            "['Deux X.']\n",
            " > Processing time: 0.1868884563446045\n",
            " > Real-time factor: 0.23308203972842356\n",
            " > Text splitted to sentences.\n",
            "['Tout cela peut être entraîné.']\n",
            " > Processing time: 2.4902310371398926\n",
            " > Real-time factor: 1.1716796340247233\n",
            " > Text splitted to sentences.\n",
            "[\"Et c'est intéressant parce que les gens ont mis tout ça là-bas.\"]\n",
            " > Processing time: 0.9671249389648438\n",
            " > Real-time factor: 0.3039496137995269\n",
            " > Text splitted to sentences.\n",
            "[\"Et ces citations ont historiquement été considérées comme un usage équitable, n'est-ce pas?\"]\n",
            " > Processing time: 1.5709199905395508\n",
            " > Real-time factor: 0.29032105564735394\n",
            " > Text splitted to sentences.\n",
            "['Les gens mettent ces citations là-haut.']\n",
            " > Processing time: 0.7525923252105713\n",
            " > Real-time factor: 0.2932333328190044\n",
            " > Text splitted to sentences.\n",
            "[\"Et individuellement, sur une base d'utilisation équitable, vous diriez, ok, c'est logique.\"]\n",
            " > Processing time: 1.0910406112670898\n",
            " > Real-time factor: 0.176291516285902\n",
            " > Text splitted to sentences.\n",
            "['Mais maintenant, il y a des gens qui font des fils.']\n",
            " > Processing time: 0.5768616199493408\n",
            " > Real-time factor: 0.17678172559321442\n",
            " > Text splitted to sentences.\n",
            "['Et au fait, il peut y avoir plusieurs personnes qui ont fait, vous savez,']\n",
            " > Processing time: 0.8646583557128906\n",
            " > Real-time factor: 0.1889940200581804\n",
            " > Text splitted to sentences.\n",
            "['un article qui a mille mots.']\n",
            " > Processing time: 0.40053534507751465\n",
            " > Real-time factor: 0.175960399246079\n",
            " > Text splitted to sentences.\n",
            "[\"Techniquement, tous les mille mots auraient pu passer à X d'une manière ou d'une autre.\"]\n",
            " > Processing time: 0.8665096759796143\n",
            " > Real-time factor: 0.18025036184292917\n",
            " > Text splitted to sentences.\n",
            "['Et effectivement, maintenant vous avez ce dépôt remarquable.']\n",
            " > Processing time: 0.6498546600341797\n",
            " > Real-time factor: 0.1782250653451948\n",
            " > Text splitted to sentences.\n",
            "['Et je me demande ce que tu penses de ça?']\n",
            " > Processing time: 0.6601519584655762\n",
            " > Real-time factor: 0.2772849490278489\n",
            " > Text splitted to sentences.\n",
            "['Encore une fois, et comment vous pensez la communauté créative.']\n",
            " > Processing time: 1.1277844905853271\n",
            " > Real-time factor: 0.29165471966370876\n",
            " > Text splitted to sentences.\n",
            "[\"Et ceux qui, étaient les propriétaires de propriété intellectuelle d'origine devraient y penser.\"]\n",
            " > Processing time: 1.5725135803222656\n",
            " > Real-time factor: 0.29440568915658505\n",
            " > Text splitted to sentences.\n",
            "[\"Je ne sais pas, sauf pour dire qu'au moment où ces poursuites sont décidées,\"]\n",
            " > Processing time: 1.233588695526123\n",
            " > Real-time factor: 0.2910528027772536\n",
            " > Text splitted to sentences.\n",
            "['Nous aurons Dieu numérique.']\n",
            " > Processing time: 0.5890035629272461\n",
            " > Real-time factor: 0.28019348814605144\n",
            " > Text splitted to sentences.\n",
            "['Donc, en tant que Dieu numérique à ce moment-là, ces procès ne seront pas décidés avant,']\n",
            " > Processing time: 1.5684151649475098\n",
            " > Real-time factor: 0.2942780325654577\n",
            " > Text splitted to sentences.\n",
            "['sur un délai qui est pertinent.']\n",
            " > Processing time: 0.6185500621795654\n",
            " > Real-time factor: 0.3026053618889647\n",
            " > Text splitted to sentences.\n",
            "[\"C'est une bonne ou une mauvaise chose?\"]\n",
            " > Processing time: 0.6475646495819092\n",
            " > Real-time factor: 0.28161092859105985\n",
            " > Text splitted to sentences.\n",
            "[\"Je pense qu'on vit, tu sais, il y a ça, je ne sais pas si c'est vraiment chinois,\"]\n",
            " > Processing time: 1.5811240673065186\n",
            " > Real-time factor: 0.29220686673686413\n",
            " > Text splitted to sentences.\n",
            "[\"n'importe lequel ou pas, mais peut-être vivre un moment intéressant.\"]\n",
            " > Processing time: 1.2890331745147705\n",
            " > Real-time factor: 0.28759087641705816\n",
            " > Text splitted to sentences.\n",
            "['Oui.']\n",
            " > Processing time: 0.22641324996948242\n",
            " > Real-time factor: 0.23198941272430704\n",
            " > Text splitted to sentences.\n",
            "[\"Et je pense que ce n'est apparemment pas une bonne chose.\"]\n",
            " > Processing time: 0.5772011280059814\n",
            " > Real-time factor: 0.1840905587903826\n",
            " > Text splitted to sentences.\n",
            "['Mais je préférerais vivre un moment intéressant.']\n",
            " > Processing time: 0.5440177917480469\n",
            " > Real-time factor: 0.1815753255637629\n",
            " > Text splitted to sentences.\n",
            "['Et nous vivons dans les moments les plus intéressants.']\n",
            " > Processing time: 0.5007777214050293\n",
            " > Real-time factor: 0.19080295750934642\n",
            " > Text splitted to sentences.\n",
            "[\"Je pense que pendant un moment, j'ai été vraiment démotivé et j'ai perdu le sommeil.\"]\n",
            " > Processing time: 0.9008898735046387\n",
            " > Real-time factor: 0.17918009192142878\n",
            " > Text splitted to sentences.\n",
            "[\"sur le genre de menace de danger d'IA.\"]\n",
            " > Processing time: 0.44536542892456055\n",
            " > Real-time factor: 0.1696901387162455\n",
            " > Text splitted to sentences.\n",
            "[\"Et puis j'ai fini par devenir fataliste à ce sujet et j'ai dit :\"]\n",
            " > Processing time: 0.760399580001831\n",
            " > Real-time factor: 0.18656323147410064\n",
            " > Text splitted to sentences.\n",
            "[\"même si je savais que c'était l'anéantissement de certains,\"]\n",
            " > Processing time: 1.0602831840515137\n",
            " > Real-time factor: 0.2889465617996821\n",
            " > Text splitted to sentences.\n",
            "[\"Est-ce que je choisirais d'être en vie à ce moment-là ou pas?\"]\n",
            " > Processing time: 0.987635612487793\n",
            " > Real-time factor: 0.2973749898317107\n",
            " > Text splitted to sentences.\n",
            "[\"Et j'ai dit, qu'elle choisirait probablement d'être vivante à ce moment-là,\"]\n",
            " > Processing time: 1.3680260181427002\n",
            " > Real-time factor: 0.30054373605179474\n",
            " > Text splitted to sentences.\n",
            "[\"Parce que c'est la chose la plus intéressante, même s'il n'y a rien que je puisse faire.\"]\n",
            " > Processing time: 3.2196340560913086\n",
            " > Real-time factor: 0.6829395387949568\n",
            " > Text splitted to sentences.\n",
            "['Donc, vous savez, puis en gros une sorte de démission fataliste']\n",
            " > Processing time: 2.183751344680786\n",
            " > Real-time factor: 0.5110345257069466\n",
            " > Text splitted to sentences.\n",
            "[\"m'a aidé à dormir la nuit, parce que j'avais du mal à dormir la nuit,\"]\n",
            " > Processing time: 2.3935627937316895\n",
            " > Real-time factor: 0.5923197567088319\n",
            " > Text splitted to sentences.\n",
            "[\"à cause du danger d'IA.\"]\n",
            " > Processing time: 1.4144704341888428\n",
            " > Real-time factor: 0.703978716907367\n",
            " > Text splitted to sentences.\n",
            "[\"Qu'est-ce qu'il y a à faire?\"]\n",
            " > Processing time: 0.42057180404663086\n",
            " > Real-time factor: 0.278520190990756\n",
            " > Text splitted to sentences.\n",
            "[\"Je veux dire, j'ai été le plus grand, celui qui frappe le tambour,\"]\n",
            " > Processing time: 1.1815452575683594\n",
            " > Real-time factor: 0.28422360937098884\n",
            " > Text splitted to sentences.\n",
            "[\"le plus dur, de loin, le plus long, ou au moins l'un des plus longs,\"]\n",
            " > Processing time: 1.161665916442871\n",
            " > Real-time factor: 0.282598559770138\n",
            " > Text splitted to sentences.\n",
            "[\"ou en danger d'IA.\"]\n",
            " > Processing time: 0.33036136627197266\n",
            " > Real-time factor: 0.16931173592174129\n",
            " > Text splitted to sentences.\n",
            "['Et ces choses réglementaires qui se produisent,']\n",
            " > Processing time: 0.5478134155273438\n",
            " > Real-time factor: 0.17801352588390018\n",
            " > Text splitted to sentences.\n",
            "[\"C'est à cause de moi qu'il s'agit de la plus grande raison.\"]\n",
            " > Processing time: 0.5974245071411133\n",
            " > Real-time factor: 0.1817897215508604\n",
            " > Text splitted to sentences.\n",
            "['Toi']\n",
            " > Processing time: 0.2631094455718994\n",
            " > Real-time factor: 0.1653432305876762\n",
            "Moviepy - Building video /content/drive/MyDrive/Colab Notebooks/CS370_project/videos1/Elon Musk OpenAI is lying when it says it is not using copyrighted data_translated.mp4.\n",
            "MoviePy - Writing audio in Elon Musk OpenAI is lying when it says it is not using copyrighted data_translatedTEMP_MPY_wvf_snd.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "Moviepy - Writing video /content/drive/MyDrive/Colab Notebooks/CS370_project/videos1/Elon Musk OpenAI is lying when it says it is not using copyrighted data_translated.mp4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "t: 100%|█████████▉| 7086/7088 [06:05<00:00, 25.94it/s, now=None]WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/moviepy/video/io/ffmpeg_reader.py:123: UserWarning: Warning: in file /content/drive/MyDrive/Colab Notebooks/CS370_project/videos1/Elon Musk OpenAI is lying when it says it is not using copyrighted data.mp4, 2764800 bytes wanted but 0 bytes read,at frame 7087/7088, at time 236.47/236.47 sec. Using the last valid frame instead.\n",
            "  warnings.warn(\"Warning: in file %s, \"%(self.filename)+\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready /content/drive/MyDrive/Colab Notebooks/CS370_project/videos1/Elon Musk OpenAI is lying when it says it is not using copyrighted data_translated.mp4\n",
            "Processed video saved at /content/drive/MyDrive/Colab Notebooks/CS370_project/videos1/Elon Musk OpenAI is lying when it says it is not using copyrighted data_translated_subtitled.mp4\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import re\n",
        "import nltk\n",
        "from pytube import YouTube\n",
        "from transformers import MarianMTModel, MarianTokenizer\n",
        "from moviepy.editor import VideoFileClip, concatenate_audioclips, AudioFileClip\n",
        "from whisper import load_model\n",
        "from TTS.api import TTS\n",
        "from pydub import AudioSegment, silence\n",
        "import pysubs2\n",
        "import subprocess\n",
        "\n",
        "nltk.download('punkt')\n",
        "model_name = 'Helsinki-NLP/opus-mt-en-fr'\n",
        "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
        "model = MarianMTModel.from_pretrained(model_name)\n",
        "tts = TTS(model_name=\"tts_models/fr/css10/vits\")\n",
        "whisper_model = load_model(\"base\")\n",
        "\n",
        "\n",
        "save_path =  \"/content/drive/MyDrive/Colab Notebooks/CS370_project/videos1\"\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "audio_folder = os.path.join(save_path, \"audio\")\n",
        "os.makedirs(audio_folder, exist_ok=True)\n",
        "tts_audio_folder = os.path.join(save_path, \"tts_audio\")\n",
        "os.makedirs(tts_audio_folder, exist_ok=True)\n",
        "\n",
        "def cleaned_video(video_name):\n",
        "    return re.sub(r'[\\\\/*?:\"<>|]', \"\", video_name)\n",
        "\n",
        "def translate(text):\n",
        "    sentences = nltk.tokenize.sent_tokenize(text)\n",
        "    translations = []\n",
        "    for sentence in sentences:\n",
        "        batch = tokenizer(sentence, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "        gen = model.generate(**batch)\n",
        "        translation = tokenizer.batch_decode(gen, skip_special_tokens=True)\n",
        "        translations.append(translation[0])\n",
        "    return ' '.join(translations)\n",
        "\n",
        "def generate_tts_audio(text, start, end, tts_audio_path):\n",
        "    tts.tts_to_file(text=text, file_path=tts_audio_path)\n",
        "    tts_audio = AudioSegment.from_mp3(tts_audio_path)\n",
        "    expected_duration = (end - start) * 1000\n",
        "    actual_duration = len(tts_audio)\n",
        "    if actual_duration < expected_duration:\n",
        "        silence_duration = expected_duration - actual_duration\n",
        "        silence_audio = AudioSegment.silent(duration=silence_duration)\n",
        "        tts_audio += silence_audio\n",
        "        tts_audio.export(tts_audio_path, format='wav')\n",
        "    return True\n",
        "\n",
        "def create_subtitles(segments, subtitles_file):\n",
        "    subs = pysubs2.SSAFile()\n",
        "    for start, end, text in segments:\n",
        "        start_ms = int(start * 1000)\n",
        "        end_ms = int(end * 1000)\n",
        "        subs.append(pysubs2.SSAEvent(start=start_ms, end=end_ms, text=text))\n",
        "    subs.save(subtitles_file)\n",
        "\n",
        "def embed_subtitles(video_path, subtitles_path, output_path):\n",
        "    command = [\n",
        "        'ffmpeg',\n",
        "        '-i', video_path,\n",
        "        '-vf', f\"subtitles={subtitles_path}\",\n",
        "        '-c:a', 'copy',\n",
        "        output_path\n",
        "    ]\n",
        "    subprocess.run(command, check=True)\n",
        "\n",
        "def process_video(url):\n",
        "    yt = YouTube(url)\n",
        "    video_id = yt.video_id\n",
        "    yt_title_cleaned = cleaned_video(yt.title)\n",
        "    video_stream = yt.streams.filter(progressive=True, file_extension='mp4').order_by('resolution').desc().first()\n",
        "\n",
        "    if not video_stream:\n",
        "        print(\"No suitable video stream found.\")\n",
        "        return None\n",
        "\n",
        "    video_path = os.path.join(save_path, yt_title_cleaned + \".mp4\")\n",
        "    video_stream.download(output_path=save_path, filename=yt_title_cleaned + \".mp4\")\n",
        "\n",
        "    video_clip = VideoFileClip(video_path)\n",
        "    audio_path = os.path.join(audio_folder, yt_title_cleaned + \".mp3\")\n",
        "    video_clip.audio.write_audiofile(audio_path)\n",
        "\n",
        "    result = whisper_model.transcribe(audio_path)\n",
        "    segments = []\n",
        "    for segment in result[\"segments\"]:\n",
        "        start_time, end_time, text = segment[\"start\"], segment[\"end\"], segment[\"text\"]\n",
        "        segments.append((start_time, end_time, text))\n",
        "\n",
        "    translated_segments = []\n",
        "    tts_clips = []\n",
        "    for start, end, text in segments:\n",
        "        translated_text = translate(text)\n",
        "        translated_segments.append((start, end, translated_text))\n",
        "\n",
        "        tts_audio_path = os.path.join(tts_audio_folder, f\"tts_{start}_{end}.wav\")\n",
        "        generate_tts_audio(translated_text, start, end, tts_audio_path)\n",
        "\n",
        "        tts_clip = AudioFileClip(tts_audio_path).subclip(0, end - start)\n",
        "        tts_clips.append(tts_clip)\n",
        "\n",
        "    combined_tts_audio = concatenate_audioclips(tts_clips)\n",
        "    final_video = video_clip.set_audio(combined_tts_audio)\n",
        "    final_video_path = os.path.join(save_path, yt_title_cleaned + \"_translated.mp4\")\n",
        "    final_video.write_videofile(final_video_path)\n",
        "\n",
        "    subtitles_file = os.path.join(save_path, yt_title_cleaned + \".srt\")\n",
        "    create_subtitles(translated_segments, subtitles_file)\n",
        "\n",
        "    embedded_video_path = os.path.join(save_path, yt_title_cleaned + \"_translated_subtitled.mp4\")\n",
        "    embed_subtitles(final_video_path, subtitles_file, embedded_video_path)\n",
        "\n",
        "    return embedded_video_path\n",
        "\n",
        "url = 'https://youtu.be/CSoXyDcUxEk?si=kwNDyTE-hIy6jpi6'\n",
        "processed_video_path = process_video(url)\n",
        "if processed_video_path:\n",
        "    print(f\"Processed video saved at {processed_video_path}\")\n",
        "else:\n",
        "    print(\"Failed to process video.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt update && sudo apt install ffmpeg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ey2g4OujKmPf",
        "outputId": "7045895e-4e62-4ca1-e88f-a0d493abe61a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rGet:1 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "\u001b[33m\r0% [Connecting to archive.ubuntu.com (185.125.190.36)] [1 InRelease 14.2 kB/110\u001b[0m\r                                                                               \rHit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Hit:5 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Get:6 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Hit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [109 kB]\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [1,520 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,294 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,535 kB]\n",
            "Fetched 4,689 kB in 3s (1,602 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "15 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 15 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ffmpeg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhEjCfrXLK12",
        "outputId": "5f8d50a0-c869-4047-a123-e7a94bcea79b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ffmpeg\n",
            "  Downloading ffmpeg-1.4.tar.gz (5.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: ffmpeg\n",
            "  Building wheel for ffmpeg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpeg: filename=ffmpeg-1.4-py3-none-any.whl size=6080 sha256=e95818aa57d5de958cd586d64236d01b0434e4f5dd42cf1dc410462209c4cc71\n",
            "  Stored in directory: /root/.cache/pip/wheels/8e/7a/69/cd6aeb83b126a7f04cbe7c9d929028dc52a6e7d525ff56003a\n",
            "Successfully built ffmpeg\n",
            "Installing collected packages: ffmpeg\n",
            "Successfully installed ffmpeg-1.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/openai/whisper.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjpIkBthJ3K5",
        "outputId": "84e0571e-c986-4bb1-b863-bdd38caca009"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-h9hkqsc5\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-h9hkqsc5\n",
            "  Resolved https://github.com/openai/whisper.git to commit e58f28804528831904c3b6f2c0e473f346223433\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: triton<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.1.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (0.58.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (1.22.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.1.0+cu118)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (4.66.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (10.1.0)\n",
            "Collecting tiktoken (from openai-whisper==20231117)\n",
            "  Downloading tiktoken-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton<3,>=2.0.0->openai-whisper==20231117) (3.13.1)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20231117) (0.41.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (2.8.8)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (2023.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper==20231117) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper==20231117) (1.3.0)\n",
            "Building wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20231117-py3-none-any.whl size=801356 sha256=8e491d2c1eb64cdc7f1e8a7d9b26fe0a96a5f025a4fe287235248f2cb69ce0bc\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-sx5nt6cp/wheels/8b/6c/d0/622666868c179f156cf595c8b6f06f88bc5d80c4b31dccaa03\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: tiktoken, openai-whisper\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed openai-whisper-20231117 tiktoken-0.5.1\n"
          ]
        }
      ]
    }
  ]
}